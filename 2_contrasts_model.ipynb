{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 constrasts model\n",
    "\n",
    "This notebook load, preprocess the data and train a first modèle to predict if a 2 image is T1w or T2w.\n",
    "The Notebook form helps running and testing fast before coding the final structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "import torchvision.models as models\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandScaleCrop,\n",
    "    RandFlip,\n",
    "    RandRotate90,\n",
    "    RandRotate,\n",
    "    RandShiftIntensity,\n",
    "    ToTensor,\n",
    "    RandSpatialCrop,\n",
    "    LoadImage,\n",
    "    SqueezeDim,\n",
    "    RandRotate,\n",
    ")\n",
    "import os\n",
    "import nibabel as nib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import monai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for T1w, T2w, and DWI files in data//data-multi-subject// ...\n",
      "Found 267 T1w files and 267 T2w files.\n"
     ]
    }
   ],
   "source": [
    "# this cell aims at extracting the list of path relevant for the first model test which takes T1w T2w adn DWI as input\n",
    "\n",
    "base_dir=\"data//data-multi-subject//\"\n",
    "\n",
    "desired_extension = \".json\"\n",
    "\n",
    "# Initialize lists to store the relative paths for T1w, T2w, and DWI files\n",
    "t1w_file_paths = []\n",
    "t2w_file_paths = []\n",
    "\n",
    "print(\"Searching for T1w, T2w, and DWI files in\", base_dir, \"...\")\n",
    "\n",
    "# Traverse the directory structure\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # Exclude the \"derivatives\" subfolder\n",
    "    if \"derivatives\" in dirs:\n",
    "        dirs.remove(\"derivatives\")\n",
    "    for file in files:\n",
    "        # Check if the file name contains the desired names\n",
    "        if \"T1w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T1w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(base_dir + relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T1w file paths list\n",
    "            t1w_file_paths.append(relative_path)\n",
    "        elif \"T2w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T2w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T2w file paths list\n",
    "            t2w_file_paths.append(base_dir + relative_path)\n",
    "\n",
    "#t1w_file_paths = t1w_file_paths[:20]\n",
    "#t2w_file_paths = t2w_file_paths[:20]\n",
    "\n",
    "print(\"Found\", len(t1w_file_paths), \"T1w files and\", len(t2w_file_paths), \"T2w files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data//data-multi-subject//sub-ucl04\\anat\\sub-ucl04_T1w.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and validation sets\n",
    "\n",
    "# build a dataset with a colmn \"file path\" wich contiains the paths listed in both t1w_file_paths and t2w_file_paths\n",
    "path_data = pd.DataFrame({\"image_path\" : t1w_file_paths + t2w_file_paths, \"labels\" : len(t1w_file_paths) * [0] + len(t2w_file_paths) * [1]})\n",
    "\n",
    "train_data, val_data = train_test_split(path_data, test_size=0.2, random_state=0)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class Dataset_2D(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.data = {\"paths\" : paths, \"labels\" : labels}\n",
    "        self.transform = transform\n",
    "        self.length = len(self.data[\"paths\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.data[\"paths\"][index]\n",
    "        label = [0,1] if self.data[\"labels\"][index] else [1,0]\n",
    "        if self.transform:\n",
    "            image = self.transform(path)\n",
    "            dim_to_squeeze = int(np.argmin(image.shape[1:])) + 1\n",
    "            image = SqueezeDim(dim=dim_to_squeeze)(image)\n",
    "            # Convert to tensor\n",
    "            image = ToTensor()(image)\n",
    "        return image, label\n",
    "    \n",
    "# use monai to define the transforms for data augmentation\n",
    "# perform the following transformations : rotation (random between +3° and -3°), flipping (random between 0°,  90 °, 180° and 270°), cropping (Random size, random place) and shifting (random shift)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        RandRotate90(prob=0.5),\n",
    "        RandFlip(prob=0.5),\n",
    "        RandShiftIntensity(offsets=0.1, prob=0.5),\n",
    "        RandRotate(range_x=3, range_y=3, range_z=3, prob=0.2),\n",
    "        RandSpatialCrop(np.array([1, 1, 1]),  max_roi_size = np.random.choice(np.array([-1,-1,1]),3, replace=False), random_size=True, random_center=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        RandSpatialCrop(np.array([1, 1, 1]),  max_roi_size = np.random.choice(np.array([-1,-1,1]),3, replace=False), random_size=True, random_center=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the custom datasets\n",
    "train_dataset = Dataset_2D(\n",
    "    paths=train_data['image_path'],\n",
    "    labels=train_data['labels'],\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "val_dataset = Dataset_2D(\n",
    "    paths=val_data['image_path'],\n",
    "    labels=val_data['labels'],\n",
    "    transform=val_transforms,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 13\n",
      "torch.Size([1, 50, 206]) [0, 1]\n",
      "Index: 14\n",
      "torch.Size([1, 189, 224]) [1, 0]\n",
      "Index: 15\n",
      "torch.Size([1, 34, 362]) [0, 1]\n",
      "Index: 16\n",
      "torch.Size([1, 5, 125]) [0, 1]\n",
      "Index: 17\n",
      "torch.Size([1, 125, 35]) [1, 0]\n",
      "Index: 18\n",
      "torch.Size([1, 44, 81]) [0, 1]\n",
      "Index: 19\n",
      "torch.Size([1, 92, 58]) [1, 0]\n",
      "Index: 20\n",
      "torch.Size([1, 29, 149]) [0, 1]\n",
      "Index: 21\n",
      "torch.Size([1, 122, 106]) [1, 0]\n",
      "Index: 22\n",
      "torch.Size([1, 28, 123]) [0, 1]\n",
      "Index: 23\n",
      "torch.Size([1, 36, 247]) [0, 1]\n",
      "Index: 24\n",
      "torch.Size([1, 61, 12]) [0, 1]\n",
      "Index: 25\n",
      "torch.Size([1, 261, 161]) [0, 1]\n",
      "Index: 26\n",
      "torch.Size([1, 6, 126]) [0, 1]\n",
      "Index: 27\n",
      "torch.Size([1, 134, 117]) [1, 0]\n",
      "Index: 28\n",
      "torch.Size([1, 52, 320]) [1, 0]\n",
      "Index: 29\n",
      "torch.Size([1, 36, 61]) [1, 0]\n",
      "Index: 30\n",
      "torch.Size([1, 3, 264]) [1, 0]\n",
      "Index: 31\n",
      "torch.Size([1, 118, 205]) [1, 0]\n",
      "Index: 32\n",
      "torch.Size([1, 134, 255]) [1, 0]\n",
      "Index: 33\n",
      "torch.Size([1, 214, 225]) [1, 0]\n",
      "Index: 34\n",
      "torch.Size([1, 178, 190]) [1, 0]\n",
      "Index: 35\n",
      "torch.Size([1, 55, 188]) [0, 1]\n",
      "Index: 36\n",
      "torch.Size([1, 60, 307]) [0, 1]\n",
      "Index: 37\n",
      "torch.Size([1, 51, 22]) [0, 1]\n",
      "Index: 38\n",
      "torch.Size([1, 111, 258]) [1, 0]\n",
      "Index: 39\n",
      "torch.Size([1, 157, 5]) [1, 0]\n",
      "Index: 40\n",
      "torch.Size([1, 122, 52]) [1, 0]\n",
      "Index: 41\n",
      "torch.Size([1, 155, 189]) [1, 0]\n",
      "Index: 42\n",
      "torch.Size([1, 240, 166]) [1, 0]\n",
      "Index: 43\n",
      "torch.Size([1, 166, 136]) [0, 1]\n",
      "Index: 44\n",
      "torch.Size([1, 191, 296]) [1, 0]\n",
      "Index: 45\n",
      "torch.Size([1, 2, 296]) [0, 1]\n",
      "Index: 46\n",
      "torch.Size([1, 73, 150]) [1, 0]\n",
      "Index: 47\n",
      "torch.Size([1, 150, 243]) [0, 1]\n",
      "Index: 48\n",
      "torch.Size([1, 145, 256]) [0, 1]\n",
      "Index: 49\n",
      "torch.Size([1, 229, 92]) [0, 1]\n",
      "Index: 50\n",
      "torch.Size([1, 297, 211]) [0, 1]\n",
      "Index: 51\n",
      "torch.Size([1, 27, 40]) [0, 1]\n",
      "Index: 52\n",
      "torch.Size([1, 5, 209]) [0, 1]\n",
      "Index: 53\n",
      "torch.Size([1, 32, 155]) [1, 0]\n",
      "Index: 54\n",
      "torch.Size([1, 81, 234]) [1, 0]\n",
      "Index: 55\n",
      "torch.Size([1, 32, 200]) [1, 0]\n",
      "Index: 56\n",
      "torch.Size([1, 162, 197]) [1, 0]\n",
      "Index: 57\n",
      "torch.Size([1, 48, 163]) [0, 1]\n",
      "Index: 58\n",
      "torch.Size([1, 149, 10]) [1, 0]\n",
      "Index: 59\n",
      "torch.Size([1, 199, 147]) [1, 0]\n",
      "Index: 60\n",
      "torch.Size([1, 31, 305]) [0, 1]\n",
      "Index: 61\n",
      "torch.Size([1, 253, 81]) [0, 1]\n",
      "Index: 62\n",
      "torch.Size([1, 54, 184]) [0, 1]\n",
      "Index: 63\n",
      "torch.Size([1, 60, 301]) [0, 1]\n",
      "Index: 64\n",
      "torch.Size([1, 129, 229]) [1, 0]\n",
      "Index: 65\n",
      "torch.Size([1, 165, 166]) [1, 0]\n",
      "Index: 66\n",
      "torch.Size([1, 191, 186]) [1, 0]\n",
      "Index: 67\n",
      "torch.Size([1, 4, 45]) [0, 1]\n",
      "Index: 68\n",
      "torch.Size([1, 142, 247]) [1, 0]\n",
      "Index: 69\n",
      "torch.Size([1, 111, 17]) [1, 0]\n",
      "Index: 70\n",
      "torch.Size([1, 81, 271]) [1, 0]\n",
      "Index: 71\n",
      "torch.Size([1, 36, 11]) [0, 1]\n",
      "Index: 72\n",
      "torch.Size([1, 310, 164]) [1, 0]\n",
      "Index: 73\n",
      "torch.Size([1, 58, 140]) [0, 1]\n",
      "Index: 74\n",
      "torch.Size([1, 40, 49]) [0, 1]\n",
      "Index: 75\n",
      "torch.Size([1, 35, 132]) [0, 1]\n",
      "Index: 76\n",
      "torch.Size([1, 78, 288]) [1, 0]\n",
      "Index: 77\n",
      "torch.Size([1, 173, 130]) [1, 0]\n",
      "Index: 78\n",
      "torch.Size([1, 241, 193]) [1, 0]\n",
      "Index: 79\n",
      "torch.Size([1, 148, 28]) [1, 0]\n",
      "Index: 80\n",
      "torch.Size([1, 146, 183]) [1, 0]\n",
      "Index: 81\n",
      "torch.Size([1, 240, 187]) [1, 0]\n",
      "Index: 82\n",
      "torch.Size([1, 106, 160]) [1, 0]\n",
      "Index: 83\n",
      "torch.Size([1, 56, 40]) [0, 1]\n",
      "Index: 84\n",
      "torch.Size([1, 76, 279]) [1, 0]\n",
      "Index: 85\n",
      "torch.Size([1, 125, 106]) [0, 1]\n",
      "Index: 86\n",
      "torch.Size([1, 53, 298]) [0, 1]\n",
      "Index: 87\n",
      "torch.Size([1, 88, 32]) [1, 0]\n",
      "Index: 88\n",
      "torch.Size([1, 62, 295]) [1, 0]\n",
      "Index: 89\n",
      "torch.Size([1, 7, 18]) [0, 1]\n",
      "Index: 90\n",
      "torch.Size([1, 17, 297]) [1, 0]\n",
      "Index: 91\n",
      "torch.Size([1, 45, 282]) [0, 1]\n",
      "Index: 92\n",
      "torch.Size([1, 107, 234]) [1, 0]\n",
      "Index: 93\n",
      "torch.Size([1, 78, 27]) [1, 0]\n",
      "Index: 94\n",
      "torch.Size([1, 124, 268]) [1, 0]\n",
      "Index: 95\n",
      "torch.Size([1, 54, 44]) [1, 0]\n",
      "Index: 96\n",
      "torch.Size([1, 57, 103]) [0, 1]\n",
      "Index: 97\n",
      "torch.Size([1, 152, 74]) [1, 0]\n",
      "Index: 98\n",
      "torch.Size([1, 146, 245]) [1, 0]\n",
      "Index: 99\n",
      "torch.Size([1, 207, 285]) [0, 1]\n",
      "Index: 100\n",
      "torch.Size([1, 178, 110]) [0, 1]\n",
      "Index: 101\n",
      "torch.Size([1, 169, 232]) [0, 1]\n",
      "Index: 102\n",
      "torch.Size([1, 250, 126]) [0, 1]\n",
      "Index: 103\n",
      "torch.Size([1, 41, 98]) [1, 0]\n",
      "Index: 104\n",
      "torch.Size([1, 32, 53]) [0, 1]\n",
      "Index: 105\n",
      "torch.Size([1, 142, 263]) [1, 0]\n",
      "Index: 106\n",
      "torch.Size([1, 40, 203]) [1, 0]\n",
      "Index: 107\n",
      "torch.Size([1, 90, 154]) [1, 0]\n",
      "Index: 108\n",
      "torch.Size([1, 165, 205]) [0, 1]\n",
      "Index: 109\n",
      "torch.Size([1, 41, 121]) [0, 1]\n",
      "Index: 110\n",
      "torch.Size([1, 47, 89]) [0, 1]\n",
      "Index: 111\n",
      "torch.Size([1, 15, 44]) [0, 1]\n",
      "Index: 112\n",
      "torch.Size([1, 1, 173]) [0, 1]\n",
      "Index: 113\n",
      "torch.Size([1, 12, 162]) [0, 1]\n",
      "Index: 114\n",
      "torch.Size([1, 220, 184]) [1, 0]\n",
      "Index: 115\n",
      "torch.Size([1, 33, 217]) [0, 1]\n",
      "Index: 116\n",
      "torch.Size([1, 128, 57]) [0, 1]\n",
      "Index: 117\n",
      "torch.Size([1, 72, 98]) [1, 0]\n",
      "Index: 118\n",
      "torch.Size([1, 60, 83]) [0, 1]\n",
      "Index: 119\n",
      "torch.Size([1, 251, 49]) [0, 1]\n",
      "Index: 120\n",
      "torch.Size([1, 44, 13]) [0, 1]\n",
      "Index: 121\n",
      "torch.Size([1, 153, 240]) [1, 0]\n",
      "Index: 122\n",
      "torch.Size([1, 65, 292]) [1, 0]\n",
      "Index: 123\n",
      "torch.Size([1, 66, 148]) [1, 0]\n",
      "Index: 124\n",
      "torch.Size([1, 15, 37]) [1, 0]\n",
      "Index: 125\n",
      "torch.Size([1, 61, 149]) [0, 1]\n",
      "Index: 126\n",
      "torch.Size([1, 17, 104]) [0, 1]\n",
      "Index: 127\n",
      "torch.Size([1, 34, 143]) [1, 0]\n",
      "Index: 128\n",
      "torch.Size([1, 259, 320]) [1, 0]\n",
      "Index: 129\n",
      "torch.Size([1, 40, 65]) [0, 1]\n",
      "Index: 130\n",
      "torch.Size([1, 3, 182]) [1, 0]\n",
      "Index: 131\n",
      "torch.Size([1, 95, 282]) [0, 1]\n",
      "Index: 132\n",
      "torch.Size([1, 6, 267]) [0, 1]\n",
      "Index: 133\n",
      "torch.Size([1, 59, 31]) [1, 0]\n",
      "Index: 134\n",
      "torch.Size([1, 151, 148]) [0, 1]\n",
      "Index: 135\n",
      "torch.Size([1, 54, 147]) [0, 1]\n",
      "Index: 136\n",
      "torch.Size([1, 66, 179]) [1, 0]\n",
      "Index: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -1.2637e-02,  7.9990e-01, -3.6361e+00],\n",
      "        [-8.0000e-01,  0.0000e+00,  0.0000e+00,  4.4262e+00],\n",
      "        [ 0.0000e+00,  7.9990e-01,  1.2637e-02, -7.4166e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 46, 21]) [0, 1]\n",
      "Index: 138\n",
      "torch.Size([1, 55, 7]) [0, 1]\n",
      "Index: 139\n",
      "torch.Size([1, 164, 203]) [1, 0]\n",
      "Index: 140\n",
      "torch.Size([1, 110, 56]) [1, 0]\n",
      "Index: 141\n",
      "torch.Size([1, 76, 125]) [1, 0]\n",
      "Index: 142\n",
      "torch.Size([1, 19, 303]) [1, 0]\n",
      "Index: 143\n",
      "torch.Size([1, 10, 24]) [0, 1]\n",
      "Index: 144\n",
      "torch.Size([1, 288, 273]) [0, 1]\n",
      "Index: 145\n",
      "torch.Size([1, 266, 60]) [0, 1]\n",
      "Index: 146\n",
      "torch.Size([1, 72, 242]) [1, 0]\n",
      "Index: 147\n",
      "torch.Size([1, 302, 15]) [0, 1]\n",
      "Index: 148\n",
      "torch.Size([1, 61, 145]) [0, 1]\n",
      "Index: 149\n",
      "torch.Size([1, 55, 151]) [0, 1]\n",
      "Index: 150\n",
      "torch.Size([1, 52, 242]) [0, 1]\n",
      "Index: 151\n",
      "torch.Size([1, 86, 247]) [1, 0]\n",
      "Index: 152\n",
      "torch.Size([1, 173, 316]) [1, 0]\n",
      "Index: 153\n",
      "torch.Size([1, 214, 160]) [1, 0]\n",
      "Index: 154\n",
      "torch.Size([1, 26, 185]) [1, 0]\n",
      "Index: 155\n",
      "torch.Size([1, 87, 159]) [0, 1]\n",
      "Index: 156\n",
      "torch.Size([1, 45, 122]) [0, 1]\n",
      "Index: 157\n",
      "torch.Size([1, 108, 190]) [1, 0]\n",
      "Index: 158\n",
      "torch.Size([1, 215, 63]) [0, 1]\n",
      "Index: 159\n",
      "torch.Size([1, 213, 207]) [0, 1]\n",
      "Index: 160\n",
      "torch.Size([1, 63, 31]) [1, 0]\n",
      "Index: 161\n",
      "torch.Size([1, 179, 249]) [1, 0]\n",
      "Index: 162\n",
      "torch.Size([1, 112, 270]) [1, 0]\n",
      "Index: 163\n",
      "torch.Size([1, 144, 282]) [1, 0]\n",
      "Index: 164\n",
      "torch.Size([1, 106, 58]) [0, 1]\n",
      "Index: 165\n",
      "torch.Size([1, 21, 225]) [1, 0]\n",
      "Index: 166\n",
      "torch.Size([1, 36, 291]) [0, 1]\n",
      "Index: 167\n",
      "torch.Size([1, 112, 94]) [1, 0]\n",
      "Index: 168\n",
      "torch.Size([1, 169, 294]) [1, 0]\n",
      "Index: 169\n",
      "torch.Size([1, 14, 81]) [0, 1]\n",
      "Index: 170\n",
      "torch.Size([1, 150, 33]) [0, 1]\n",
      "Index: 171\n",
      "torch.Size([1, 224, 293]) [0, 1]\n",
      "Index: 172\n",
      "torch.Size([1, 3, 21]) [1, 0]\n",
      "Index: 173\n",
      "torch.Size([1, 28, 205]) [0, 1]\n",
      "Index: 174\n",
      "torch.Size([1, 143, 127]) [1, 0]\n",
      "Index: 175\n",
      "torch.Size([1, 21, 74]) [0, 1]\n",
      "Index: 176\n",
      "torch.Size([1, 20, 160]) [0, 1]\n",
      "Index: 177\n",
      "torch.Size([1, 213, 245]) [0, 1]\n",
      "Index: 178\n",
      "torch.Size([1, 58, 218]) [1, 0]\n",
      "Index: 179\n",
      "torch.Size([1, 107, 40]) [1, 0]\n",
      "Index: 180\n",
      "torch.Size([1, 117, 238]) [1, 0]\n",
      "Index: 181\n",
      "torch.Size([1, 94, 117]) [1, 0]\n",
      "Index: 182\n",
      "torch.Size([1, 25, 2]) [1, 0]\n",
      "Index: 183\n",
      "torch.Size([1, 189, 274]) [1, 0]\n",
      "Index: 184\n",
      "torch.Size([1, 117, 143]) [1, 0]\n",
      "Index: 185\n",
      "torch.Size([1, 175, 24]) [1, 0]\n",
      "Index: 186\n",
      "torch.Size([1, 30, 69]) [0, 1]\n",
      "Index: 187\n",
      "torch.Size([1, 17, 142]) [0, 1]\n",
      "Index: 188\n",
      "torch.Size([1, 33, 222]) [0, 1]\n",
      "Index: 189\n",
      "torch.Size([1, 35, 89]) [0, 1]\n",
      "Index: 190\n",
      "torch.Size([1, 101, 303]) [1, 0]\n",
      "Index: 191\n",
      "torch.Size([1, 50, 201]) [0, 1]\n",
      "Index: 192\n",
      "torch.Size([1, 18, 123]) [1, 0]\n",
      "Index: 193\n",
      "torch.Size([1, 142, 189]) [0, 1]\n",
      "Index: 194\n",
      "torch.Size([1, 234, 167]) [1, 0]\n",
      "Index: 195\n",
      "torch.Size([1, 16, 172]) [0, 1]\n",
      "Index: 196\n",
      "torch.Size([1, 64, 133]) [1, 0]\n",
      "Index: 197\n",
      "torch.Size([1, 31, 40]) [0, 1]\n",
      "Index: 198\n",
      "torch.Size([1, 18, 282]) [0, 1]\n",
      "Index: 199\n",
      "torch.Size([1, 20, 131]) [0, 1]\n",
      "Index: 200\n",
      "torch.Size([1, 136, 299]) [1, 0]\n",
      "Index: 201\n",
      "torch.Size([1, 165, 303]) [1, 0]\n",
      "Index: 202\n",
      "torch.Size([1, 200, 280]) [0, 1]\n",
      "Index: 203\n",
      "torch.Size([1, 4, 301]) [0, 1]\n",
      "Index: 204\n",
      "torch.Size([1, 151, 232]) [1, 0]\n",
      "Index: 205\n",
      "torch.Size([1, 34, 209]) [0, 1]\n",
      "Index: 206\n",
      "torch.Size([1, 22, 52]) [0, 1]\n",
      "Index: 207\n",
      "torch.Size([1, 149, 31]) [1, 0]\n",
      "Index: 208\n",
      "torch.Size([1, 157, 314]) [1, 0]\n",
      "Index: 209\n",
      "torch.Size([1, 172, 190]) [1, 0]\n",
      "Index: 210\n",
      "torch.Size([1, 213, 197]) [0, 1]\n",
      "Index: 211\n",
      "torch.Size([1, 275, 282]) [0, 1]\n",
      "Index: 212\n",
      "torch.Size([1, 185, 59]) [0, 1]\n",
      "Index: 213\n",
      "torch.Size([1, 63, 257]) [1, 0]\n",
      "Index: 214\n",
      "torch.Size([1, 51, 253]) [0, 1]\n",
      "Index: 215\n",
      "torch.Size([1, 188, 268]) [1, 0]\n",
      "Index: 216\n",
      "torch.Size([1, 132, 309]) [1, 0]\n",
      "Index: 217\n",
      "torch.Size([1, 318, 26]) [0, 1]\n",
      "Index: 218\n",
      "torch.Size([1, 358, 78]) [1, 0]\n",
      "Index: 219\n",
      "torch.Size([1, 1, 300]) [1, 0]\n",
      "Index: 220\n",
      "torch.Size([1, 106, 319]) [1, 0]\n",
      "Index: 221\n",
      "torch.Size([1, 13, 4]) [1, 0]\n",
      "Index: 222\n",
      "torch.Size([1, 105, 95]) [1, 0]\n",
      "Index: 223\n",
      "torch.Size([1, 142, 107]) [1, 0]\n",
      "Index: 224\n",
      "torch.Size([1, 310, 220]) [0, 1]\n",
      "Index: 225\n",
      "torch.Size([1, 156, 309]) [1, 0]\n",
      "Index: 226\n",
      "torch.Size([1, 185, 78]) [1, 0]\n",
      "Index: 227\n",
      "torch.Size([1, 140, 299]) [1, 0]\n",
      "Index: 228\n",
      "torch.Size([1, 35, 38]) [1, 0]\n",
      "Index: 229\n",
      "torch.Size([1, 42, 252]) [0, 1]\n",
      "Index: 230\n",
      "torch.Size([1, 218, 44]) [0, 1]\n",
      "Index: 231\n",
      "torch.Size([1, 106, 53]) [1, 0]\n",
      "Index: 232\n",
      "torch.Size([1, 54, 154]) [0, 1]\n",
      "Index: 233\n",
      "torch.Size([1, 19, 27]) [0, 1]\n",
      "Index: 234\n",
      "torch.Size([1, 194, 15]) [1, 0]\n",
      "Index: 235\n",
      "torch.Size([1, 52, 51]) [0, 1]\n",
      "Index: 236\n",
      "torch.Size([1, 152, 178]) [0, 1]\n",
      "Index: 237\n",
      "torch.Size([1, 36, 67]) [0, 1]\n",
      "Index: 238\n",
      "torch.Size([1, 68, 275]) [1, 0]\n",
      "Index: 239\n",
      "torch.Size([1, 53, 93]) [0, 1]\n",
      "Index: 240\n",
      "torch.Size([1, 11, 88]) [0, 1]\n",
      "Index: 241\n",
      "torch.Size([1, 293, 293]) [0, 1]\n",
      "Index: 242\n",
      "torch.Size([1, 47, 42]) [1, 0]\n",
      "Index: 243\n",
      "torch.Size([1, 38, 98]) [1, 0]\n",
      "Index: 244\n",
      "torch.Size([1, 90, 304]) [1, 0]\n",
      "Index: 245\n",
      "torch.Size([1, 120, 251]) [1, 0]\n",
      "Index: 246\n",
      "torch.Size([1, 222, 248]) [1, 0]\n",
      "Index: 247\n",
      "torch.Size([1, 113, 281]) [1, 0]\n",
      "Index: 248\n",
      "torch.Size([1, 74, 301]) [1, 0]\n",
      "Index: 249\n",
      "torch.Size([1, 191, 136]) [1, 0]\n",
      "Index: 250\n",
      "torch.Size([1, 202, 103]) [1, 0]\n",
      "Index: 251\n",
      "torch.Size([1, 110, 275]) [1, 0]\n",
      "Index: 252\n",
      "torch.Size([1, 135, 293]) [0, 1]\n",
      "Index: 253\n",
      "torch.Size([1, 58, 165]) [0, 1]\n",
      "Index: 254\n",
      "torch.Size([1, 153, 267]) [1, 0]\n",
      "Index: 255\n",
      "torch.Size([1, 43, 187]) [0, 1]\n",
      "Index: 256\n",
      "torch.Size([1, 169, 59]) [1, 0]\n",
      "Index: 257\n",
      "torch.Size([1, 311, 49]) [1, 0]\n",
      "Index: 258\n",
      "torch.Size([1, 28, 274]) [1, 0]\n",
      "Index: 259\n",
      "torch.Size([1, 280, 258]) [0, 1]\n",
      "Index: 260\n",
      "torch.Size([1, 289, 232]) [0, 1]\n",
      "Index: 261\n",
      "torch.Size([1, 36, 173]) [0, 1]\n",
      "Index: 262\n",
      "torch.Size([1, 35, 29]) [0, 1]\n",
      "Index: 263\n",
      "torch.Size([1, 13, 154]) [0, 1]\n",
      "Index: 264\n",
      "torch.Size([1, 27, 289]) [1, 0]\n",
      "Index: 265\n",
      "torch.Size([1, 20, 103]) [0, 1]\n",
      "Index: 266\n",
      "torch.Size([1, 14, 30]) [0, 1]\n",
      "Index: 267\n",
      "torch.Size([1, 179, 171]) [1, 0]\n",
      "Index: 268\n",
      "torch.Size([1, 16, 55]) [0, 1]\n",
      "Index: 269\n",
      "torch.Size([1, 7, 58]) [0, 1]\n",
      "Index: 270\n",
      "torch.Size([1, 77, 34]) [0, 1]\n",
      "Index: 271\n",
      "torch.Size([1, 239, 4]) [0, 1]\n",
      "Index: 272\n",
      "torch.Size([1, 36, 72]) [0, 1]\n",
      "Index: 273\n",
      "torch.Size([1, 62, 105]) [1, 0]\n",
      "Index: 274\n",
      "torch.Size([1, 31, 35]) [0, 1]\n",
      "Index: 275\n",
      "torch.Size([1, 228, 270]) [1, 0]\n",
      "Index: 276\n",
      "torch.Size([1, 40, 211]) [0, 1]\n",
      "Index: 277\n",
      "torch.Size([1, 253, 213]) [1, 0]\n",
      "Index: 278\n",
      "torch.Size([1, 29, 16]) [0, 1]\n",
      "Index: 279\n",
      "torch.Size([1, 35, 176]) [0, 1]\n",
      "Index: 280\n",
      "torch.Size([1, 229, 155]) [1, 0]\n",
      "Index: 281\n",
      "torch.Size([1, 29, 15]) [1, 0]\n",
      "Index: 282\n",
      "torch.Size([1, 12, 153]) [0, 1]\n",
      "Index: 283\n",
      "torch.Size([1, 318, 285]) [0, 1]\n",
      "Index: 284\n",
      "torch.Size([1, 18, 141]) [0, 1]\n",
      "Index: 285\n",
      "torch.Size([1, 247, 185]) [0, 1]\n",
      "Index: 286\n",
      "torch.Size([1, 2, 9]) [0, 1]\n",
      "Index: 287\n",
      "torch.Size([1, 104, 19]) [0, 1]\n",
      "Index: 288\n",
      "torch.Size([1, 85, 166]) [1, 0]\n",
      "Index: 289\n",
      "torch.Size([1, 99, 223]) [1, 0]\n",
      "Index: 290\n",
      "torch.Size([1, 177, 12]) [1, 0]\n",
      "Index: 291\n",
      "torch.Size([1, 54, 294]) [0, 1]\n",
      "Index: 292\n",
      "torch.Size([1, 159, 226]) [1, 0]\n",
      "Index: 293\n",
      "torch.Size([1, 184, 194]) [1, 0]\n",
      "Index: 294\n",
      "torch.Size([1, 5, 301]) [0, 1]\n",
      "Index: 295\n",
      "torch.Size([1, 52, 129]) [0, 1]\n",
      "Index: 296\n",
      "torch.Size([1, 55, 267]) [1, 0]\n",
      "Index: 297\n",
      "torch.Size([1, 113, 91]) [1, 0]\n",
      "Index: 298\n",
      "torch.Size([1, 146, 250]) [1, 0]\n",
      "Index: 299\n",
      "torch.Size([1, 157, 254]) [1, 0]\n",
      "Index: 300\n",
      "torch.Size([1, 39, 188]) [1, 0]\n",
      "Index: 301\n",
      "torch.Size([1, 326, 424]) [1, 0]\n",
      "Index: 302\n",
      "torch.Size([1, 9, 188]) [0, 1]\n",
      "Index: 303\n",
      "torch.Size([1, 165, 247]) [1, 0]\n",
      "Index: 304\n",
      "torch.Size([1, 191, 308]) [1, 0]\n",
      "Index: 305\n",
      "torch.Size([1, 24, 168]) [0, 1]\n",
      "Index: 306\n",
      "torch.Size([1, 22, 279]) [0, 1]\n",
      "Index: 307\n",
      "torch.Size([1, 46, 171]) [0, 1]\n",
      "Index: 308\n",
      "torch.Size([1, 163, 30]) [1, 0]\n",
      "Index: 309\n",
      "torch.Size([1, 64, 13]) [1, 0]\n",
      "Index: 310\n",
      "torch.Size([1, 81, 57]) [1, 0]\n",
      "Index: 311\n",
      "torch.Size([1, 54, 62]) [0, 1]\n",
      "Index: 312\n",
      "torch.Size([1, 46, 18]) [0, 1]\n",
      "Index: 313\n",
      "torch.Size([1, 15, 137]) [1, 0]\n",
      "Index: 314\n",
      "torch.Size([1, 121, 307]) [1, 0]\n",
      "Index: 315\n",
      "torch.Size([1, 163, 201]) [1, 0]\n",
      "Index: 316\n",
      "torch.Size([1, 45, 174]) [0, 1]\n",
      "Index: 317\n",
      "torch.Size([1, 154, 70]) [1, 0]\n",
      "Index: 318\n",
      "torch.Size([1, 115, 73]) [0, 1]\n",
      "Index: 319\n",
      "torch.Size([1, 8, 49]) [0, 1]\n",
      "Index: 320\n",
      "torch.Size([1, 49, 251]) [1, 0]\n",
      "Index: 321\n",
      "torch.Size([1, 54, 297]) [0, 1]\n",
      "Index: 322\n",
      "torch.Size([1, 226, 177]) [1, 0]\n",
      "Index: 323\n",
      "torch.Size([1, 48, 197]) [0, 1]\n",
      "Index: 324\n",
      "torch.Size([1, 306, 270]) [0, 1]\n",
      "Index: 325\n",
      "torch.Size([1, 162, 178]) [0, 1]\n",
      "Index: 326\n",
      "torch.Size([1, 156, 62]) [1, 0]\n",
      "Index: 327\n",
      "torch.Size([1, 57, 40]) [0, 1]\n",
      "Index: 328\n",
      "torch.Size([1, 254, 260]) [0, 1]\n",
      "Index: 329\n",
      "torch.Size([1, 75, 48]) [0, 1]\n",
      "Index: 330\n",
      "torch.Size([1, 12, 196]) [0, 1]\n",
      "Index: 331\n",
      "torch.Size([1, 1, 173]) [0, 1]\n",
      "Index: 332\n",
      "torch.Size([1, 191, 184]) [1, 0]\n",
      "Index: 333\n",
      "torch.Size([1, 18, 24]) [0, 1]\n",
      "Index: 334\n",
      "torch.Size([1, 62, 247]) [1, 0]\n",
      "Index: 335\n",
      "torch.Size([1, 43, 190]) [1, 0]\n",
      "Index: 336\n",
      "torch.Size([1, 88, 165]) [1, 0]\n",
      "Index: 337\n",
      "torch.Size([1, 186, 150]) [1, 0]\n",
      "Index: 338\n",
      "torch.Size([1, 8, 153]) [0, 1]\n",
      "Index: 339\n",
      "torch.Size([1, 215, 210]) [1, 0]\n",
      "Index: 340\n",
      "torch.Size([1, 175, 17]) [1, 0]\n",
      "Index: 341\n",
      "torch.Size([1, 43, 179]) [0, 1]\n",
      "Index: 342\n",
      "torch.Size([1, 65, 163]) [1, 0]\n",
      "Index: 343\n",
      "torch.Size([1, 294, 49]) [0, 1]\n",
      "Index: 344\n",
      "torch.Size([1, 27, 151]) [0, 1]\n",
      "Index: 345\n",
      "torch.Size([1, 47, 79]) [0, 1]\n",
      "Index: 346\n",
      "torch.Size([1, 282, 315]) [1, 0]\n",
      "Index: 347\n",
      "torch.Size([1, 19, 43]) [0, 1]\n",
      "Index: 348\n",
      "torch.Size([1, 22, 260]) [0, 1]\n",
      "Index: 349\n",
      "torch.Size([1, 167, 53]) [1, 0]\n",
      "Index: 350\n",
      "torch.Size([1, 121, 77]) [1, 0]\n",
      "Index: 351\n",
      "torch.Size([1, 7, 16]) [1, 0]\n",
      "Index: 352\n",
      "torch.Size([1, 4, 107]) [0, 1]\n",
      "Index: 353\n",
      "torch.Size([1, 159, 171]) [1, 0]\n",
      "Index: 354\n",
      "torch.Size([1, 16, 51]) [0, 1]\n",
      "Index: 355\n",
      "torch.Size([1, 64, 37]) [0, 1]\n",
      "Index: 356\n",
      "torch.Size([1, 7, 280]) [1, 0]\n",
      "Index: 357\n",
      "torch.Size([1, 74, 290]) [1, 0]\n",
      "Index: 358\n",
      "torch.Size([1, 170, 96]) [1, 0]\n",
      "Index: 359\n",
      "torch.Size([1, 40, 144]) [0, 1]\n",
      "Index: 360\n",
      "torch.Size([1, 95, 90]) [1, 0]\n",
      "Index: 361\n",
      "torch.Size([1, 33, 312]) [0, 1]\n",
      "Index: 362\n",
      "torch.Size([1, 225, 88]) [1, 0]\n",
      "Index: 363\n",
      "torch.Size([1, 54, 281]) [1, 0]\n",
      "Index: 364\n",
      "torch.Size([1, 47, 32]) [0, 1]\n",
      "Index: 365\n",
      "torch.Size([1, 77, 246]) [1, 0]\n",
      "Index: 366\n",
      "torch.Size([1, 272, 64]) [0, 1]\n",
      "Index: 367\n",
      "torch.Size([1, 14, 170]) [0, 1]\n",
      "Index: 368\n",
      "torch.Size([1, 114, 173]) [0, 1]\n",
      "Index: 369\n",
      "torch.Size([1, 61, 130]) [0, 1]\n",
      "Index: 370\n",
      "torch.Size([1, 11, 181]) [0, 1]\n",
      "Index: 371\n",
      "torch.Size([1, 158, 197]) [1, 0]\n",
      "Index: 372\n",
      "torch.Size([1, 219, 281]) [1, 0]\n",
      "Index: 373\n",
      "torch.Size([1, 54, 214]) [0, 1]\n",
      "Index: 374\n",
      "torch.Size([1, 53, 180]) [0, 1]\n",
      "Index: 375\n",
      "torch.Size([1, 139, 168]) [1, 0]\n",
      "Index: 376\n",
      "torch.Size([1, 57, 22]) [0, 1]\n",
      "Index: 377\n",
      "torch.Size([1, 172, 165]) [0, 1]\n",
      "Index: 378\n",
      "torch.Size([1, 95, 40]) [1, 0]\n",
      "Index: 379\n",
      "torch.Size([1, 17, 225]) [0, 1]\n",
      "Index: 380\n",
      "torch.Size([1, 18, 206]) [0, 1]\n",
      "Index: 381\n",
      "torch.Size([1, 43, 264]) [1, 0]\n",
      "Index: 382\n",
      "torch.Size([1, 156, 214]) [0, 1]\n",
      "Index: 383\n",
      "torch.Size([1, 55, 280]) [1, 0]\n",
      "Index: 384\n",
      "torch.Size([1, 57, 267]) [0, 1]\n",
      "Index: 385\n",
      "torch.Size([1, 124, 203]) [1, 0]\n",
      "Index: 386\n",
      "torch.Size([1, 152, 110]) [1, 0]\n",
      "Index: 387\n",
      "torch.Size([1, 8, 14]) [0, 1]\n",
      "Index: 388\n",
      "torch.Size([1, 23, 192]) [0, 1]\n",
      "Index: 389\n",
      "torch.Size([1, 106, 182]) [0, 1]\n",
      "Index: 390\n",
      "torch.Size([1, 216, 142]) [0, 1]\n",
      "Index: 391\n",
      "torch.Size([1, 12, 96]) [0, 1]\n",
      "Index: 392\n",
      "torch.Size([1, 167, 284]) [1, 0]\n",
      "Index: 393\n",
      "torch.Size([1, 59, 25]) [0, 1]\n",
      "Index: 394\n",
      "torch.Size([1, 136, 96]) [1, 0]\n",
      "Index: 395\n",
      "torch.Size([1, 60, 3]) [0, 1]\n",
      "Index: 396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -1.8870e-02, -7.9978e-01, -9.2078e+00],\n",
      "        [ 8.0000e-01,  0.0000e+00,  0.0000e+00, -1.1801e+02],\n",
      "        [ 0.0000e+00, -7.9978e-01,  1.8870e-02,  5.3359e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 74, 16]) [0, 1]\n",
      "Index: 397\n",
      "torch.Size([1, 112, 1]) [1, 0]\n",
      "Index: 398\n",
      "torch.Size([1, 11, 103]) [0, 1]\n",
      "Index: 399\n",
      "torch.Size([1, 71, 151]) [1, 0]\n",
      "Index: 400\n",
      "torch.Size([1, 138, 73]) [1, 0]\n",
      "Index: 401\n",
      "torch.Size([1, 61, 119]) [0, 1]\n",
      "Index: 402\n",
      "torch.Size([1, 39, 144]) [0, 1]\n",
      "Index: 403\n",
      "torch.Size([1, 127, 43]) [1, 0]\n",
      "Index: 404\n",
      "torch.Size([1, 167, 183]) [1, 0]\n",
      "Index: 405\n",
      "torch.Size([1, 191, 53]) [1, 0]\n",
      "Index: 406\n",
      "torch.Size([1, 88, 165]) [1, 0]\n",
      "Index: 407\n",
      "torch.Size([1, 128, 155]) [0, 1]\n",
      "Index: 408\n",
      "torch.Size([1, 50, 130]) [0, 1]\n",
      "Index: 409\n",
      "torch.Size([1, 118, 192]) [1, 0]\n",
      "Index: 410\n",
      "torch.Size([1, 219, 48]) [1, 0]\n",
      "Index: 411\n",
      "torch.Size([1, 78, 318]) [1, 0]\n",
      "Index: 412\n",
      "torch.Size([1, 51, 100]) [0, 1]\n",
      "Index: 413\n",
      "torch.Size([1, 47, 42]) [0, 1]\n",
      "Index: 414\n"
     ]
    }
   ],
   "source": [
    "# get an image\n",
    "for i in range(13, train_dataset.length):\n",
    "    print(\"Index:\", i)\n",
    "    image, label = train_dataset[i]\n",
    "    print(image.shape, label)\n",
    "\n",
    "\n",
    "# plot the image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image[0, :, :])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dim must be None or a int but is int64.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m rd_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, N)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print the rd_index-th image\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrd_index\u001b[49m\u001b[43m]\u001b[49m)\n",
      "Cell \u001b[1;32mIn[36], line 16\u001b[0m, in \u001b[0;36mDataset_2D.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(path)\n\u001b[0;32m     15\u001b[0m dim_to_squeeze \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mSqueezeDim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_to_squeeze\u001b[49m\u001b[43m)\u001b[49m(image)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[0;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m ToTensor()(image)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:570\u001b[0m, in \u001b[0;36mSqueezeDim.__init__\u001b[1;34m(self, dim, update_meta)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m    dim: dimension to be squeezed. Default = 0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m \n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 570\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim must be None or a int but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dim)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m dim\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_meta \u001b[38;5;241m=\u001b[39m update_meta\n",
      "\u001b[1;31mTypeError\u001b[0m: dim must be None or a int but is int64."
     ]
    }
   ],
   "source": [
    "# Build the training and validation datasets\n",
    "train_dataset = Dataset_2D(train_data['image_path'], train_data['label'], transform=train_transforms)\n",
    "#val_dataset = Dataset_2D(val_data['image_path'], val_data['label'], transform=val_transforms)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=10)\n",
    "\n",
    "N = len(train_dataset.data)\n",
    "for i in range(10):\n",
    "    rd_index = np.random.randint(0, N)\n",
    "    # print the rd_index-th image\n",
    "    print(train_dataset[rd_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5767, 0.5020],\n",
      "        [0.8802, 0.8488],\n",
      "        [0.0636, 0.6604]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)  \u001b[38;5;66;03m# torch.Size([5, 2]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#print(output.squeeze(-1).shape)  # torch.Size([2, 4])\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class ResNet18SingleChannel(nn.Module):\n",
    "    # Define the ResNet18 model with a single input channel and an output value between 0 and 1\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18SingleChannel, self).__init__()\n",
    "        # Load the pre-trained ResNet18 model\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Modify the first convolutional layer to take a single channel input\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        # Modify the final fully connected layer to output a single value\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "        #final fc to go from [batch_size, 1000] to [batch_size, num_classes]\n",
    "        self.fc = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ResNet18SingleChannel(num_classes=2).to(device)\n",
    "\n",
    "#output = model.forward(torch.randn(3, 1, 49, 29))\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "print(f\"Validation accuracy: {correct / total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
