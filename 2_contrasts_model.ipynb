{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 constrasts model\n",
    "\n",
    "This notebook load, preprocess the data and train a first modèle to predict if a 2 image is T1w or T2w.\n",
    "The Notebook form helps running and testing fast before coding the final structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    ToTensord,\n",
    ")\n",
    "import os\n",
    "import nibabel as nib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell aims at extracting the list of path relevant for the first model test which takes T1w T2w adn DWI as input\n",
    "\n",
    "base_dir=\"data//data-multi-subject//\"\n",
    "\n",
    "desired_extension = \".json\"\n",
    "\n",
    "# Initialize lists to store the relative paths for T1w, T2w, and DWI files\n",
    "t1w_file_paths = []\n",
    "t2w_file_paths = []\n",
    "\n",
    "print(\"Searching for T1w, T2w, and DWI files in\", base_dir, \"...\")\n",
    "\n",
    "# Traverse the directory structure\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # Exclude the \"derivatives\" subfolder\n",
    "    if \"derivatives\" in dirs:\n",
    "        dirs.remove(\"derivatives\")\n",
    "    for file in files:\n",
    "        # Check if the file name contains the desired names\n",
    "        if \"T1w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T1w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T1w file paths list\n",
    "            t1w_file_paths.append(relative_path)\n",
    "        elif \"T2w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T2w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T2w file paths list\n",
    "            t2w_file_paths.append(relative_path)\n",
    "\n",
    "print(\"Found\", len(t1w_file_paths), \"T1w files and\", len(t2w_file_paths), \"T2w files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img_data\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define a custom dataset class\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a function to load image data\n",
    "def load_image(image_path):\n",
    "    img = nib.load(image_path)\n",
    "    img_data = img.get_fdata()\n",
    "    return img_data\n",
    "\n",
    "def From_3D_to_2Ds(image, label):\n",
    "    #from each 3D image we will extract 10 2D images, from random different views\n",
    "    data_2D=[]\n",
    "    selected_perax=[[],[],[]] #list of the selected indexes for each view\n",
    "    for i in range(10):\n",
    "        # randomly select a view\n",
    "        view = np.random.choice([0, 1, 2]) # 0: sagittal, 1: coronal, 2: axial\n",
    "        # randomly select an index for wich we will extract the 2D image among the index which were not yet selected\n",
    "        index = np.random.choice([i for i in range(image.shape[view]) if i not in selected_perax[view]])\n",
    "        if view == 0:\n",
    "            image_2D = image[index, :, :]\n",
    "        elif view == 1:\n",
    "            image_2D = image[:, index, :]\n",
    "        else:\n",
    "            image_2D = image[:, :, index]\n",
    "        selected_perax[view].append(index)\n",
    "        data_2D.append({\"image\" : image_2D, \"label\" : label})\n",
    "    return(data_2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "path_data = pd.DataFrame({\"image_path\": t1w_file_paths, \"label\": [1,0]})\n",
    "path_data = path_data.append(pd.DataFrame({\"image_path\": t2w_file_paths, \"label\": [0,1]}), ignore_index=True)\n",
    "train_data, val_data = train_test_split(path_data, test_size=0.2, random_state=0)\n",
    "\n",
    "# load the 3D images\n",
    "train_data_2D = []\n",
    "val_data_2D = []\n",
    "for index, row in train_data.iterrows():\n",
    "    image_path = os.path.join(base_dir, row[\"image_path\"])\n",
    "    image = load_image(image_path)\n",
    "    train_data_2D += From_3D_to_2Ds(image, row[\"label\"])\n",
    "for index, row in val_data.iterrows():\n",
    "    image_path = os.path.join(base_dir, row[\"image_path\"])\n",
    "    image = load_image(image_path)\n",
    "    val_data_2D += From_3D_to_2Ds(image, row[\"label\"])\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.shuffle(train_data_2D)\n",
    "np.random.shuffle(val_data_2D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_item = self.data[index]\n",
    "        image = data_item[\"image\"]\n",
    "        label = data_item[\"label\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "# use monai to define the transforms for data augmentation\n",
    "# perform the following transformations : rotation (random between +3° and -3°), flipping (random between 0°,  90 °, 180° and 270°), cropping (Random size, random place) and shifting (random shift)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        RandRotate90d(keys=[\"image\"], prob=0.5),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5),\n",
    "        RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "        ToTensord(keys=[\"image\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and validation transforms\n",
    "# Define transforms for training data\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=\"image\"),\n",
    "        AddChanneld(keys=\"image\"),\n",
    "        Spacingd(keys=\"image\", pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=\"image\", axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=\"image\", a_min=-65, a_max=405, b_min=0.0, b_max=1.0, clip=True),\n",
    "        RandCropByPosNegLabeld(keys=\"image\", label_key=\"label\", spatial_size=(96, 96, 96), pos=1, neg=1, num_samples=4),\n",
    "        RandFlipd(keys=\"image\", prob=0.5, spatial_axis=0),\n",
    "        RandRotate90d(keys=\"image\", prob=0.5, max_k=3),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
    "        ToTensord(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define transforms for testing data\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=\"image\"),\n",
    "        AddChanneld(keys=\"image\"),\n",
    "        Spacingd(keys=\"image\", pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=\"image\", axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=\"image\", a_min=-65, a_max=405, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ToTensord(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LoadImaged: Load the image data from the specified keys\n",
    "# AddChanneld: Add a channel dimension to the image data\n",
    "# Spacingd: Resample the image data to have a specified pixel dimension and interpolation mode\n",
    "# Orientationd: Reorient the image data to have a specified axis code\n",
    "# ScaleIntensityRanged: Scale the intensity values of the image data to a specified range\n",
    "# RandCropByPosNegLabeld: Randomly crop the image data based on positive and negative labels\n",
    "# RandFlipd: Randomly flip the image data along the specified spatial axis\n",
    "# RandRotate90d: Randomly rotate the image data by 90 degrees\n",
    "# RandShiftIntensityd: Randomly shift the intensity values of the image data\n",
    "# ToTensord: Convert the image data to a tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
