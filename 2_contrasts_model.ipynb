{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 constrasts model\n",
    "\n",
    "This notebook load, preprocess the data and train a first modèle to predict if a 2 image is T1w or T2w.\n",
    "The Notebook form helps running and testing fast before coding the final structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "import torchvision.models as models\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandScaleCrop,\n",
    "    RandFlip,\n",
    "    RandRotate90,\n",
    "    RandRotate,\n",
    "    RandShiftIntensity,\n",
    "    ToTensor,\n",
    "    RandSpatialCrop,\n",
    "    LoadImage,\n",
    "    SqueezeDim,\n",
    "    RandRotate,\n",
    ")\n",
    "import os\n",
    "import nibabel as nib\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import monai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for T1w, T2w, and DWI files in data//data-multi-subject// ...\n",
      "Found 267 T1w files and 267 T2w files.\n"
     ]
    }
   ],
   "source": [
    "# this cell aims at extracting the list of path relevant for the first model test which takes T1w T2w adn DWI as image\n",
    "\n",
    "base_dir=\"data//data-multi-subject//\"\n",
    "\n",
    "desired_extension = \".json\"\n",
    "\n",
    "# Initialize lists to store the relative paths for T1w, T2w, and DWI files\n",
    "t1w_file_paths = []\n",
    "t2w_file_paths = []\n",
    "\n",
    "print(\"Searching for T1w, T2w, and DWI files in\", base_dir, \"...\")\n",
    "\n",
    "# Traverse the directory structure\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # Exclude the \"derivatives\" subfolder\n",
    "    if \"derivatives\" in dirs:\n",
    "        dirs.remove(\"derivatives\")\n",
    "    for file in files:\n",
    "        # Check if the file name contains the desired names\n",
    "        if \"T1w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T1w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(base_dir + relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T1w file paths list\n",
    "            t1w_file_paths.append(relative_path)\n",
    "        elif \"T2w\" in file and file.endswith(desired_extension):\n",
    "            # Get the relative path of the T2w file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "            # Remove the file extension\n",
    "            relative_path = os.path.splitext(relative_path)[0] + \".nii.gz\"\n",
    "            # Append the relative path to the T2w file paths list\n",
    "            t2w_file_paths.append(base_dir + relative_path)\n",
    "\n",
    "#t1w_file_paths = t1w_file_paths[:20]\n",
    "#t2w_file_paths = t2w_file_paths[:20]\n",
    "\n",
    "print(\"Found\", len(t1w_file_paths), \"T1w files and\", len(t2w_file_paths), \"T2w files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "\n",
    "# build a dataset with a colmn \"file path\" wich contiains the paths listed in both t1w_file_paths and t2w_file_paths\n",
    "path_data = pd.DataFrame({\"image_path\" : t1w_file_paths + t2w_file_paths, \"labels\" : len(t1w_file_paths) * [0] + len(t2w_file_paths) * [1]})\n",
    "\n",
    "train_data, val_data = train_test_split(path_data, test_size=0.2, random_state=0)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class Dataset_2D(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.data = {\"paths\" : paths, \"labels\" : labels}\n",
    "        self.transform = transform\n",
    "        self.length = len(self.data[\"paths\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.data[\"paths\"][index]\n",
    "        label = [0,1] if self.data[\"labels\"][index] else [1,0]\n",
    "        if self.transform:\n",
    "            image = self.transform(path)\n",
    "            dim_to_squeeze = int(np.random.choice([0,1,2]))\n",
    "            roi_min = np.array([15, 15, 15])\n",
    "            roi_max = np.array([-1, -1, -1])\n",
    "            roi_min[dim_to_squeeze] = 1\n",
    "            roi_max[dim_to_squeeze] = 1\n",
    "            image = RandSpatialCrop(roi_min,  max_roi_size = roi_max, random_size=True, random_center=True)(image)\n",
    "            image = SqueezeDim(dim=dim_to_squeeze + 1)(image)\n",
    "            # Convert to tensor\n",
    "            image = ToTensor()(image)\n",
    "            # add a dimension to the image, for exemple [1, 256, 256] -> [1, 1, 256, 256]\n",
    "            image = image.unsqueeze(0)\n",
    "\n",
    "        # convert label list to tensor with shape [1,2]\n",
    "        label = torch.tensor([label])\n",
    "        return image, label\n",
    "    \n",
    "# use monai to define the transforms for data augmentation\n",
    "# perform the following transformations : rotation (random between +3° and -3°), flipping (random between 0°,  90 °, 180° and 270°), cropping (Random size, random place) and shifting (random shift)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        RandRotate90(prob=0.5),\n",
    "        RandFlip(prob=0.5),\n",
    "        RandShiftIntensity(offsets=0.1, prob=0.5),\n",
    "        RandRotate(range_x=3, range_y=3, range_z=3, prob=0.2),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the custom datasets\n",
    "train_dataset = Dataset_2D(\n",
    "    paths=train_data['image_path'],\n",
    "    labels=train_data['labels'],\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "val_dataset = Dataset_2D(\n",
    "    paths=val_data['image_path'],\n",
    "    labels=val_data['labels'],\n",
    "    transform=val_transforms,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 143\n",
      "torch.Size([1, 1, 55, 301]) tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# get an image\n",
    "i = np.random.randint(0, train_dataset.length)\n",
    "print(\"Index:\", i)\n",
    "image, label = train_dataset[i]\n",
    "print(image.shape, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor([[[[1.0714, 2.0714, 3.0714,  ..., 2.0714, 2.0714, 3.0714],\n",
      "          [6.0714, 2.0714, 1.0714,  ..., 0.0714, 2.0714, 3.0714],\n",
      "          [3.0714, 1.0714, 3.0714,  ..., 1.0714, 2.0714, 1.0714],\n",
      "          ...,\n",
      "          [3.0714, 2.0714, 2.0714,  ..., 3.0714, 2.0714, 3.0714],\n",
      "          [2.0714, 4.0714, 4.0714,  ..., 3.0714, 3.0714, 3.0714],\n",
      "          [6.0714, 6.0714, 2.0714,  ..., 2.0714, 3.0714, 3.0714]]]])\n",
      "metatensor([[0.5073, 0.5722]], grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ResNet18SingleChannel(nn.Module):\n",
    "    # Define the ResNet18 model with a single image channel and an output value between 0 and 1\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18SingleChannel, self).__init__()\n",
    "        # Load the pre-trained ResNet18 model\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Modify the first convolutional layer to take a single channel input\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        # Modify the final fully connected layer to output a single value\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "        #final fc to go from [batch_size, 1000] to [batch_size, num_classes]\n",
    "        self.fc = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ResNet18SingleChannel(num_classes=2).to(device)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image)\n",
    "output = model.forward(image.to(device))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "Training...\n",
      "Model in training mode\n",
      "Training on image  355\n",
      "torch.Size([1, 1, 24, 296])\n",
      "Training on image  353\n",
      "torch.Size([1, 1, 125, 98])\n",
      "Training on image  231\n",
      "torch.Size([1, 1, 26, 246])\n",
      "Training on image  1\n",
      "torch.Size([1, 1, 51, 124])\n",
      "Training on image  95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -5.2965e-03,  1.0000e+00, -2.0622e+01],\n",
      "        [-1.0000e+00,  0.0000e+00,  0.0000e+00,  2.6243e+01],\n",
      "        [ 0.0000e+00,  9.9999e-01,  5.2966e-03, -7.7048e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 94, 56])\n",
      "Training on image  36\n",
      "torch.Size([1, 1, 23, 299])\n",
      "Training on image  113\n",
      "torch.Size([1, 1, 136, 302])\n",
      "Training on image  181\n",
      "torch.Size([1, 1, 178, 211])\n",
      "Training on image  397\n",
      "torch.Size([1, 1, 68, 282])\n",
      "Training on image  272\n",
      "torch.Size([1, 1, 59, 38])\n",
      "Training on image  296\n",
      "torch.Size([1, 1, 183, 187])\n",
      "Training on image  135\n",
      "torch.Size([1, 1, 254, 21])\n",
      "Training on image  199\n",
      "torch.Size([1, 1, 38, 304])\n",
      "Training on image  78\n",
      "torch.Size([1, 1, 110, 154])\n",
      "Training on image  167\n",
      "torch.Size([1, 1, 136, 299])\n",
      "Training on image  121\n",
      "torch.Size([1, 1, 34, 48])\n",
      "Training on image  40\n",
      "torch.Size([1, 1, 172, 214])\n",
      "Training on image  212\n",
      "torch.Size([1, 1, 49, 146])\n",
      "Training on image  403\n",
      "torch.Size([1, 1, 72, 102])\n",
      "Training on image  269\n",
      "torch.Size([1, 1, 204, 137])\n",
      "Training on image  107\n",
      "torch.Size([1, 1, 15, 180])\n",
      "Training on image  168\n",
      "torch.Size([1, 1, 112, 103])\n",
      "Training on image  160\n",
      "torch.Size([1, 1, 134, 302])\n",
      "Training on image  81\n",
      "torch.Size([1, 1, 187, 103])\n",
      "Training on image  115\n",
      "torch.Size([1, 1, 54, 29])\n",
      "Training on image  308\n",
      "torch.Size([1, 1, 205, 52])\n",
      "Training on image  122\n",
      "torch.Size([1, 1, 101, 171])\n",
      "Training on image  419\n",
      "torch.Size([1, 1, 42, 55])\n",
      "Training on image  339\n",
      "torch.Size([1, 1, 241, 313])\n",
      "Training on image  178\n",
      "torch.Size([1, 1, 152, 101])\n",
      "Training on image  39\n",
      "torch.Size([1, 1, 15, 171])\n",
      "Training on image  5\n",
      "torch.Size([1, 1, 244, 300])\n",
      "Training on image  59\n",
      "torch.Size([1, 1, 205, 317])\n",
      "Training on image  228\n",
      "torch.Size([1, 1, 148, 101])\n",
      "Training on image  373\n",
      "torch.Size([1, 1, 192, 27])\n",
      "Training on image  191\n",
      "torch.Size([1, 1, 159, 33])\n",
      "Training on image  246\n",
      "torch.Size([1, 1, 113, 258])\n",
      "Training on image  365\n",
      "torch.Size([1, 1, 112, 185])\n",
      "Training on image  405\n",
      "torch.Size([1, 1, 259, 171])\n",
      "Training on image  327\n",
      "torch.Size([1, 1, 68, 110])\n",
      "Training on image  314\n",
      "torch.Size([1, 1, 185, 32])\n",
      "Training on image  253\n",
      "torch.Size([1, 1, 36, 109])\n",
      "Training on image  58\n",
      "torch.Size([1, 1, 192, 75])\n",
      "Training on image  347\n",
      "torch.Size([1, 1, 20, 85])\n",
      "Training on image  358\n",
      "torch.Size([1, 1, 139, 71])\n",
      "Training on image  417\n",
      "torch.Size([1, 1, 146, 107])\n",
      "Training on image  42\n",
      "torch.Size([1, 1, 51, 76])\n",
      "Training on image  371\n",
      "torch.Size([1, 1, 37, 157])\n",
      "Training on image  260\n",
      "torch.Size([1, 1, 252, 109])\n",
      "Training on image  82\n",
      "torch.Size([1, 1, 221, 101])\n",
      "Training on image  227\n",
      "torch.Size([1, 1, 87, 142])\n",
      "Training on image  219\n",
      "torch.Size([1, 1, 89, 203])\n",
      "Training on image  297\n",
      "torch.Size([1, 1, 151, 250])\n",
      "Training on image  2\n",
      "torch.Size([1, 1, 180, 200])\n",
      "Training on image  362\n",
      "torch.Size([1, 1, 178, 284])\n",
      "Training on image  139\n",
      "torch.Size([1, 1, 69, 162])\n",
      "Training on image  282\n",
      "torch.Size([1, 1, 29, 141])\n",
      "Training on image  310\n",
      "torch.Size([1, 1, 170, 201])\n",
      "Training on image  13\n",
      "torch.Size([1, 1, 30, 109])\n",
      "Training on image  136\n",
      "torch.Size([1, 1, 187, 42])\n",
      "Training on image  323\n",
      "torch.Size([1, 1, 41, 114])\n",
      "Training on image  243\n",
      "torch.Size([1, 1, 154, 266])\n",
      "Training on image  350\n",
      "torch.Size([1, 1, 82, 42])\n",
      "Training on image  214\n",
      "torch.Size([1, 1, 33, 59])\n",
      "Training on image  241\n",
      "torch.Size([1, 1, 210, 138])\n",
      "Training on image  363\n",
      "torch.Size([1, 1, 117, 29])\n",
      "Training on image  426\n",
      "torch.Size([1, 1, 35, 60])\n",
      "Training on image  49\n",
      "torch.Size([1, 1, 87, 17])\n",
      "Training on image  76\n",
      "torch.Size([1, 1, 38, 82])\n",
      "Training on image  117\n",
      "torch.Size([1, 1, 179, 196])\n",
      "Training on image  147\n",
      "torch.Size([1, 1, 198, 32])\n",
      "Training on image  257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00,  2.8356e-02,  9.9959e-01,  6.1151e+01],\n",
      "        [-1.0002e+00,  0.0000e+00,  0.0000e+00, -8.2081e+01],\n",
      "        [ 0.0000e+00,  9.9982e-01, -2.8350e-02,  9.1249e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 36, 30])\n",
      "Training on image  261\n",
      "torch.Size([1, 1, 30, 166])\n",
      "Training on image  263\n",
      "torch.Size([1, 1, 283, 18])\n",
      "Training on image  6\n",
      "torch.Size([1, 1, 177, 274])\n",
      "Training on image  254\n",
      "torch.Size([1, 1, 247, 246])\n",
      "Training on image  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -2.2680e-02, -7.9968e-01,  6.0325e+00],\n",
      "        [ 8.0000e-01,  0.0000e+00,  0.0000e+00, -5.2215e+01],\n",
      "        [ 0.0000e+00, -7.9968e-01,  2.2680e-02,  8.1739e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 113, 37])\n",
      "Training on image  252\n",
      "torch.Size([1, 1, 285, 24])\n",
      "Training on image  141\n",
      "torch.Size([1, 1, 71, 58])\n",
      "Training on image  23\n",
      "torch.Size([1, 1, 38, 62])\n",
      "Training on image  27\n",
      "torch.Size([1, 1, 210, 310])\n",
      "Training on image  164\n",
      "torch.Size([1, 1, 20, 316])\n",
      "Training on image  415\n",
      "torch.Size([1, 1, 233, 164])\n",
      "Training on image  143\n",
      "torch.Size([1, 1, 305, 115])\n",
      "Training on image  408\n",
      "torch.Size([1, 1, 57, 237])\n",
      "Training on image  92\n",
      "torch.Size([1, 1, 163, 204])\n",
      "Training on image  22\n",
      "torch.Size([1, 1, 44, 295])\n",
      "Training on image  372\n",
      "torch.Size([1, 1, 117, 275])\n",
      "Training on image  10\n",
      "torch.Size([1, 1, 18, 172])\n",
      "Training on image  289\n",
      "torch.Size([1, 1, 43, 143])\n",
      "Training on image  198\n",
      "torch.Size([1, 1, 224, 185])\n",
      "Training on image  329\n",
      "torch.Size([1, 1, 21, 434])\n",
      "Training on image  30\n",
      "torch.Size([1, 1, 54, 234])\n",
      "Training on image  64\n",
      "torch.Size([1, 1, 28, 64])\n",
      "Training on image  48\n",
      "torch.Size([1, 1, 35, 177])\n",
      "Training on image  337\n",
      "torch.Size([1, 1, 131, 26])\n",
      "Training on image  309\n",
      "torch.Size([1, 1, 90, 252])\n",
      "Training on image  390\n",
      "torch.Size([1, 1, 292, 320])\n",
      "Training on image  146\n",
      "torch.Size([1, 1, 20, 315])\n",
      "Training on image  322\n",
      "torch.Size([1, 1, 96, 317])\n",
      "Training on image  367\n",
      "torch.Size([1, 1, 31, 127])\n",
      "Training on image  245\n",
      "torch.Size([1, 1, 57, 297])\n",
      "Training on image  47\n",
      "torch.Size([1, 1, 302, 50])\n",
      "Training on image  197\n",
      "torch.Size([1, 1, 23, 126])\n",
      "Training on image  66\n",
      "torch.Size([1, 1, 59, 69])\n",
      "Training on image  124\n",
      "torch.Size([1, 1, 111, 23])\n",
      "Training on image  280\n",
      "torch.Size([1, 1, 213, 23])\n",
      "Training on image  161\n",
      "torch.Size([1, 1, 126, 83])\n",
      "Training on image  131\n",
      "torch.Size([1, 1, 167, 171])\n",
      "Training on image  129\n",
      "torch.Size([1, 1, 26, 278])\n",
      "Training on image  110\n",
      "torch.Size([1, 1, 78, 23])\n",
      "Training on image  101\n",
      "torch.Size([1, 1, 304, 140])\n",
      "Training on image  61\n",
      "torch.Size([1, 1, 46, 260])\n",
      "Training on image  88\n",
      "torch.Size([1, 1, 68, 37])\n",
      "Training on image  116\n",
      "torch.Size([1, 1, 43, 143])\n",
      "Training on image  150\n",
      "torch.Size([1, 1, 51, 168])\n",
      "Training on image  342\n",
      "torch.Size([1, 1, 127, 143])\n",
      "Training on image  224\n",
      "torch.Size([1, 1, 34, 130])\n",
      "Training on image  360\n",
      "torch.Size([1, 1, 289, 110])\n",
      "Training on image  201\n",
      "torch.Size([1, 1, 204, 29])\n",
      "Training on image  60\n",
      "torch.Size([1, 1, 56, 18])\n",
      "Training on image  321\n",
      "torch.Size([1, 1, 24, 303])\n",
      "Training on image  238\n",
      "torch.Size([1, 1, 111, 111])\n",
      "Training on image  9\n",
      "torch.Size([1, 1, 189, 32])\n",
      "Training on image  299\n",
      "torch.Size([1, 1, 207, 136])\n",
      "Training on image  158\n",
      "torch.Size([1, 1, 90, 196])\n",
      "Training on image  391\n",
      "torch.Size([1, 1, 26, 281])\n",
      "Training on image  352\n",
      "torch.Size([1, 1, 15, 169])\n",
      "Training on image  15\n",
      "torch.Size([1, 1, 50, 309])\n",
      "Training on image  175\n",
      "torch.Size([1, 1, 88, 67])\n",
      "Training on image  125\n",
      "torch.Size([1, 1, 37, 252])\n",
      "Training on image  54\n",
      "torch.Size([1, 1, 53, 65])\n",
      "Training on image  416\n",
      "torch.Size([1, 1, 134, 257])\n",
      "Training on image  50\n",
      "torch.Size([1, 1, 193, 201])\n",
      "Training on image  265\n",
      "torch.Size([1, 1, 27, 293])\n",
      "Training on image  305\n",
      "torch.Size([1, 1, 56, 81])\n",
      "Training on image  93\n",
      "torch.Size([1, 1, 34, 186])\n",
      "Training on image  374\n",
      "torch.Size([1, 1, 50, 251])\n",
      "Training on image  311\n",
      "torch.Size([1, 1, 248, 228])\n",
      "Training on image  52\n",
      "torch.Size([1, 1, 46, 39])\n",
      "Training on image  3\n",
      "torch.Size([1, 1, 18, 230])\n",
      "Training on image  73\n",
      "torch.Size([1, 1, 186, 313])\n",
      "Training on image  315\n",
      "torch.Size([1, 1, 82, 175])\n",
      "Training on image  179\n",
      "torch.Size([1, 1, 110, 171])\n",
      "Training on image  422\n",
      "torch.Size([1, 1, 69, 34])\n",
      "Training on image  119\n",
      "torch.Size([1, 1, 135, 57])\n",
      "Training on image  345\n",
      "torch.Size([1, 1, 44, 251])\n",
      "Training on image  151\n",
      "torch.Size([1, 1, 106, 58])\n",
      "Training on image  344\n",
      "torch.Size([1, 1, 62, 292])\n",
      "Training on image  142\n",
      "torch.Size([1, 1, 69, 77])\n",
      "Training on image  221\n",
      "torch.Size([1, 1, 182, 71])\n",
      "Training on image  346\n",
      "torch.Size([1, 1, 285, 142])\n",
      "Training on image  378\n",
      "torch.Size([1, 1, 149, 281])\n",
      "Training on image  395\n",
      "torch.Size([1, 1, 193, 262])\n",
      "Training on image  188\n",
      "torch.Size([1, 1, 288, 122])\n",
      "Training on image  7\n",
      "torch.Size([1, 1, 206, 166])\n",
      "Training on image  33\n",
      "torch.Size([1, 1, 40, 135])\n",
      "Training on image  303\n",
      "torch.Size([1, 1, 83, 259])\n",
      "Training on image  271\n",
      "torch.Size([1, 1, 25, 53])\n",
      "Training on image  163\n",
      "torch.Size([1, 1, 38, 203])\n",
      "Training on image  216\n",
      "torch.Size([1, 1, 281, 125])\n",
      "Training on image  306\n",
      "torch.Size([1, 1, 51, 57])\n",
      "Training on image  65\n",
      "torch.Size([1, 1, 44, 235])\n",
      "Training on image  208\n",
      "torch.Size([1, 1, 148, 91])\n",
      "Training on image  281\n",
      "torch.Size([1, 1, 102, 78])\n",
      "Training on image  420\n",
      "torch.Size([1, 1, 59, 248])\n",
      "Training on image  153\n",
      "torch.Size([1, 1, 144, 224])\n",
      "Training on image  418\n",
      "torch.Size([1, 1, 49, 283])\n",
      "Training on image  402\n",
      "torch.Size([1, 1, 24, 27])\n",
      "Training on image  11\n",
      "torch.Size([1, 1, 47, 50])\n",
      "Training on image  288\n",
      "torch.Size([1, 1, 20, 209])\n",
      "Training on image  31\n",
      "torch.Size([1, 1, 191, 15])\n",
      "Training on image  240\n",
      "torch.Size([1, 1, 159, 220])\n",
      "Training on image  138\n",
      "torch.Size([1, 1, 44, 78])\n",
      "Training on image  185\n",
      "torch.Size([1, 1, 170, 29])\n",
      "Training on image  232\n",
      "torch.Size([1, 1, 18, 282])\n",
      "Training on image  409\n",
      "torch.Size([1, 1, 68, 191])\n",
      "Training on image  204\n",
      "torch.Size([1, 1, 31, 174])\n",
      "Training on image  171\n",
      "torch.Size([1, 1, 15, 79])\n",
      "Training on image  255\n",
      "torch.Size([1, 1, 16, 284])\n",
      "Training on image  134\n",
      "torch.Size([1, 1, 28, 207])\n",
      "Training on image  108\n",
      "torch.Size([1, 1, 40, 33])\n",
      "Training on image  96\n",
      "torch.Size([1, 1, 223, 246])\n",
      "Training on image  106\n",
      "torch.Size([1, 1, 188, 20])\n",
      "Training on image  28\n",
      "torch.Size([1, 1, 180, 208])\n",
      "Training on image  71\n",
      "torch.Size([1, 1, 47, 249])\n",
      "Training on image  298\n",
      "torch.Size([1, 1, 394, 33])\n",
      "Training on image  176\n",
      "torch.Size([1, 1, 298, 57])\n",
      "Training on image  366\n",
      "torch.Size([1, 1, 285, 103])\n",
      "Training on image  154\n",
      "torch.Size([1, 1, 74, 401])\n",
      "Training on image  392\n",
      "torch.Size([1, 1, 58, 403])\n",
      "Training on image  237\n",
      "torch.Size([1, 1, 255, 126])\n",
      "Training on image  234\n",
      "torch.Size([1, 1, 182, 259])\n",
      "Training on image  316\n",
      "torch.Size([1, 1, 52, 310])\n",
      "Training on image  130\n",
      "torch.Size([1, 1, 173, 251])\n",
      "Training on image  53\n",
      "torch.Size([1, 1, 147, 65])\n",
      "Training on image  313\n",
      "torch.Size([1, 1, 120, 223])\n",
      "Training on image  348\n",
      "torch.Size([1, 1, 104, 37])\n",
      "Training on image  370\n",
      "torch.Size([1, 1, 33, 99])\n",
      "Training on image  336\n",
      "torch.Size([1, 1, 128, 260])\n",
      "Training on image  99\n",
      "torch.Size([1, 1, 34, 81])\n",
      "Training on image  111\n",
      "torch.Size([1, 1, 48, 116])\n",
      "Training on image  21\n",
      "torch.Size([1, 1, 87, 270])\n",
      "Training on image  203\n",
      "torch.Size([1, 1, 57, 182])\n",
      "Training on image  46\n",
      "torch.Size([1, 1, 23, 222])\n",
      "Training on image  248\n",
      "torch.Size([1, 1, 130, 83])\n",
      "Training on image  90\n",
      "torch.Size([1, 1, 313, 22])\n",
      "Training on image  244\n",
      "torch.Size([1, 1, 17, 90])\n",
      "Training on image  91\n",
      "torch.Size([1, 1, 34, 67])\n",
      "Training on image  275\n",
      "torch.Size([1, 1, 28, 219])\n",
      "Training on image  41\n",
      "torch.Size([1, 1, 21, 45])\n",
      "Training on image  249\n",
      "torch.Size([1, 1, 143, 66])\n",
      "Training on image  295\n",
      "torch.Size([1, 1, 42, 153])\n",
      "Training on image  32\n",
      "torch.Size([1, 1, 203, 198])\n",
      "Training on image  126\n",
      "torch.Size([1, 1, 47, 155])\n",
      "Training on image  207\n",
      "torch.Size([1, 1, 48, 161])\n",
      "Training on image  51\n",
      "torch.Size([1, 1, 289, 162])\n",
      "Training on image  359\n",
      "torch.Size([1, 1, 30, 176])\n",
      "Training on image  4\n",
      "torch.Size([1, 1, 191, 219])\n",
      "Training on image  382\n",
      "torch.Size([1, 1, 19, 34])\n",
      "Training on image  105\n",
      "torch.Size([1, 1, 34, 187])\n",
      "Training on image  375\n",
      "torch.Size([1, 1, 75, 139])\n",
      "Training on image  127\n",
      "torch.Size([1, 1, 146, 232])\n",
      "Training on image  277\n",
      "torch.Size([1, 1, 34, 69])\n",
      "Training on image  286\n",
      "torch.Size([1, 1, 24, 291])\n",
      "Training on image  170\n",
      "torch.Size([1, 1, 62, 161])\n",
      "Training on image  120\n",
      "torch.Size([1, 1, 27, 314])\n",
      "Training on image  332\n",
      "torch.Size([1, 1, 86, 206])\n",
      "Training on image  128\n",
      "torch.Size([1, 1, 52, 129])\n",
      "Training on image  338\n",
      "torch.Size([1, 1, 24, 74])\n",
      "Training on image  326\n",
      "torch.Size([1, 1, 142, 276])\n",
      "Training on image  229\n",
      "torch.Size([1, 1, 98, 153])\n",
      "Training on image  226\n",
      "torch.Size([1, 1, 168, 31])\n",
      "Training on image  97\n",
      "torch.Size([1, 1, 161, 20])\n",
      "Training on image  34\n",
      "torch.Size([1, 1, 117, 160])\n",
      "Training on image  274\n",
      "torch.Size([1, 1, 19, 216])\n",
      "Training on image  206\n",
      "torch.Size([1, 1, 42, 225])\n",
      "Training on image  324\n",
      "torch.Size([1, 1, 20, 259])\n",
      "Training on image  328\n",
      "torch.Size([1, 1, 143, 252])\n",
      "Training on image  196\n",
      "torch.Size([1, 1, 198, 239])\n",
      "Training on image  62\n",
      "torch.Size([1, 1, 69, 216])\n",
      "Training on image  225\n",
      "torch.Size([1, 1, 285, 219])\n",
      "Training on image  18\n",
      "torch.Size([1, 1, 57, 16])\n",
      "Training on image  251\n",
      "torch.Size([1, 1, 169, 129])\n",
      "Training on image  144\n",
      "torch.Size([1, 1, 60, 223])\n",
      "Training on image  194\n",
      "torch.Size([1, 1, 126, 286])\n",
      "Training on image  401\n",
      "torch.Size([1, 1, 22, 315])\n",
      "Training on image  407\n",
      "torch.Size([1, 1, 55, 227])\n",
      "Training on image  404\n",
      "torch.Size([1, 1, 38, 175])\n",
      "Training on image  268\n",
      "torch.Size([1, 1, 32, 273])\n",
      "Training on image  230\n",
      "torch.Size([1, 1, 29, 68])\n",
      "Training on image  398\n",
      "torch.Size([1, 1, 18, 232])\n",
      "Training on image  80\n",
      "torch.Size([1, 1, 261, 259])\n",
      "Training on image  294\n",
      "torch.Size([1, 1, 142, 56])\n",
      "Training on image  343\n",
      "torch.Size([1, 1, 279, 47])\n",
      "Training on image  340\n",
      "torch.Size([1, 1, 189, 144])\n",
      "Training on image  174\n",
      "torch.Size([1, 1, 116, 213])\n",
      "Training on image  63\n",
      "torch.Size([1, 1, 163, 70])\n",
      "Training on image  70\n",
      "torch.Size([1, 1, 112, 67])\n",
      "Training on image  114\n",
      "torch.Size([1, 1, 168, 106])\n",
      "Training on image  200\n",
      "torch.Size([1, 1, 162, 57])\n",
      "Training on image  56\n",
      "torch.Size([1, 1, 48, 58])\n",
      "Training on image  159\n",
      "torch.Size([1, 1, 302, 67])\n",
      "Training on image  8\n",
      "torch.Size([1, 1, 20, 305])\n",
      "Training on image  133\n",
      "torch.Size([1, 1, 20, 254])\n",
      "Training on image  17\n",
      "torch.Size([1, 1, 114, 184])\n",
      "Training on image  26\n",
      "torch.Size([1, 1, 39, 112])\n",
      "Training on image  189\n",
      "torch.Size([1, 1, 28, 237])\n",
      "Training on image  195\n",
      "torch.Size([1, 1, 242, 44])\n",
      "Training on image  425\n",
      "torch.Size([1, 1, 55, 36])\n",
      "Training on image  186\n",
      "torch.Size([1, 1, 487, 16])\n",
      "Training on image  341\n",
      "torch.Size([1, 1, 23, 19])\n",
      "Training on image  222\n",
      "torch.Size([1, 1, 82, 270])\n",
      "Training on image  276\n",
      "torch.Size([1, 1, 304, 265])\n",
      "Training on image  364\n",
      "torch.Size([1, 1, 42, 177])\n",
      "Training on image  213\n",
      "torch.Size([1, 1, 49, 53])\n",
      "Training on image  192\n",
      "torch.Size([1, 1, 111, 78])\n",
      "Training on image  20\n",
      "torch.Size([1, 1, 26, 135])\n",
      "Training on image  100\n",
      "torch.Size([1, 1, 27, 41])\n",
      "Training on image  183\n",
      "torch.Size([1, 1, 226, 279])\n",
      "Training on image  45\n",
      "torch.Size([1, 1, 50, 120])\n",
      "Training on image  354\n",
      "torch.Size([1, 1, 51, 28])\n",
      "Training on image  335\n",
      "torch.Size([1, 1, 114, 203])\n",
      "Training on image  413\n",
      "torch.Size([1, 1, 27, 239])\n",
      "Training on image  85\n",
      "torch.Size([1, 1, 246, 126])\n",
      "Training on image  396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00,  1.8870e-02,  7.9978e-01, -5.3758e+00],\n",
      "        [-8.0000e-01,  0.0000e+00,  0.0000e+00, -5.2409e+01],\n",
      "        [ 0.0000e+00,  7.9978e-01, -1.8870e-02, -5.5562e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 59, 33])\n",
      "Training on image  190\n",
      "torch.Size([1, 1, 237, 265])\n",
      "Training on image  381\n",
      "torch.Size([1, 1, 29, 215])\n",
      "Training on image  236\n",
      "torch.Size([1, 1, 52, 261])\n",
      "Training on image  77\n",
      "torch.Size([1, 1, 16, 197])\n",
      "Training on image  220\n",
      "torch.Size([1, 1, 186, 319])\n",
      "Training on image  72\n",
      "torch.Size([1, 1, 301, 161])\n",
      "Training on image  387\n",
      "torch.Size([1, 1, 191, 86])\n",
      "Training on image  217\n",
      "torch.Size([1, 1, 83, 276])\n",
      "Training on image  145\n",
      "torch.Size([1, 1, 64, 258])\n",
      "Training on image  331\n",
      "torch.Size([1, 1, 52, 124])\n",
      "Training on image  368\n",
      "torch.Size([1, 1, 90, 146])\n",
      "Training on image  388\n",
      "torch.Size([1, 1, 32, 181])\n",
      "Training on image  187\n",
      "torch.Size([1, 1, 37, 264])\n",
      "Training on image  155\n",
      "torch.Size([1, 1, 284, 88])\n",
      "Training on image  184\n",
      "torch.Size([1, 1, 19, 245])\n",
      "Training on image  291\n",
      "torch.Size([1, 1, 51, 228])\n",
      "Training on image  14\n",
      "torch.Size([1, 1, 288, 75])\n",
      "Training on image  109\n",
      "torch.Size([1, 1, 60, 225])\n",
      "Training on image  152\n",
      "torch.Size([1, 1, 140, 158])\n",
      "Training on image  330\n",
      "torch.Size([1, 1, 18, 39])\n",
      "Training on image  38\n",
      "torch.Size([1, 1, 90, 59])\n",
      "Training on image  264\n",
      "torch.Size([1, 1, 134, 179])\n",
      "Training on image  148\n",
      "torch.Size([1, 1, 151, 280])\n",
      "Training on image  312\n",
      "torch.Size([1, 1, 102, 160])\n",
      "Training on image  180\n",
      "torch.Size([1, 1, 122, 43])\n",
      "Training on image  182\n",
      "torch.Size([1, 1, 132, 225])\n",
      "Training on image  83\n",
      "torch.Size([1, 1, 28, 46])\n",
      "Training on image  166\n",
      "torch.Size([1, 1, 159, 63])\n",
      "Training on image  29\n",
      "torch.Size([1, 1, 244, 17])\n",
      "Training on image  307\n",
      "torch.Size([1, 1, 34, 320])\n",
      "Training on image  424\n",
      "torch.Size([1, 1, 62, 50])\n",
      "Training on image  287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00,  3.4767e-02,  7.9924e-01, -4.3796e+00],\n",
      "        [-8.0000e-01,  0.0000e+00,  0.0000e+00,  1.0099e+02],\n",
      "        [ 0.0000e+00,  7.9924e-01, -3.4767e-02,  6.3333e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 306, 34])\n",
      "Training on image  256\n",
      "torch.Size([1, 1, 44, 117])\n",
      "Training on image  270\n",
      "torch.Size([1, 1, 210, 94])\n",
      "Training on image  377\n",
      "torch.Size([1, 1, 152, 164])\n",
      "Training on image  383\n",
      "torch.Size([1, 1, 48, 169])\n",
      "Training on image  74\n",
      "torch.Size([1, 1, 37, 213])\n",
      "Training on image  394\n",
      "torch.Size([1, 1, 25, 236])\n",
      "Training on image  140\n",
      "torch.Size([1, 1, 36, 201])\n",
      "Training on image  75\n",
      "torch.Size([1, 1, 219, 35])\n",
      "Training on image  55\n",
      "torch.Size([1, 1, 122, 163])\n",
      "Training on image  193\n",
      "torch.Size([1, 1, 22, 45])\n",
      "Training on image  112\n",
      "torch.Size([1, 1, 166, 268])\n",
      "Training on image  24\n",
      "torch.Size([1, 1, 61, 220])\n",
      "Training on image  400\n",
      "torch.Size([1, 1, 313, 128])\n",
      "Training on image  266\n",
      "torch.Size([1, 1, 276, 48])\n",
      "Training on image  319\n",
      "torch.Size([1, 1, 303, 225])\n",
      "Training on image  87\n",
      "torch.Size([1, 1, 148, 125])\n",
      "Training on image  399\n",
      "torch.Size([1, 1, 89, 174])\n",
      "Training on image  301\n",
      "torch.Size([1, 1, 157, 159])\n",
      "Training on image  25\n",
      "torch.Size([1, 1, 247, 205])\n",
      "Training on image  0\n",
      "torch.Size([1, 1, 60, 162])\n",
      "Training on image  84\n",
      "torch.Size([1, 1, 61, 32])\n",
      "Training on image  349\n",
      "torch.Size([1, 1, 108, 218])\n",
      "Training on image  86\n",
      "torch.Size([1, 1, 15, 291])\n",
      "Training on image  273\n",
      "torch.Size([1, 1, 128, 318])\n",
      "Training on image  278\n",
      "torch.Size([1, 1, 23, 187])\n",
      "Training on image  173\n",
      "torch.Size([1, 1, 33, 177])\n",
      "Training on image  410\n",
      "torch.Size([1, 1, 72, 264])\n",
      "Training on image  233\n",
      "torch.Size([1, 1, 243, 254])\n",
      "Training on image  356\n",
      "torch.Size([1, 1, 39, 65])\n",
      "Training on image  37\n",
      "torch.Size([1, 1, 129, 18])\n",
      "Training on image  379\n",
      "torch.Size([1, 1, 27, 142])\n",
      "Training on image  69\n",
      "torch.Size([1, 1, 250, 136])\n",
      "Training on image  411\n",
      "torch.Size([1, 1, 26, 286])\n",
      "Training on image  300\n",
      "torch.Size([1, 1, 153, 254])\n",
      "Training on image  317\n",
      "torch.Size([1, 1, 23, 105])\n",
      "Training on image  267\n",
      "torch.Size([1, 1, 91, 70])\n",
      "Training on image  162\n",
      "torch.Size([1, 1, 126, 64])\n",
      "Training on image  137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00,  1.2637e-02, -7.9990e-01,  1.9791e+01],\n",
      "        [ 8.0000e-01,  0.0000e+00,  0.0000e+00,  8.6826e+01],\n",
      "        [ 0.0000e+00, -7.9990e-01, -1.2637e-02,  1.1423e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 41, 51])\n",
      "Training on image  423\n",
      "torch.Size([1, 1, 25, 67])\n",
      "Training on image  205\n",
      "torch.Size([1, 1, 43, 113])\n",
      "Training on image  210\n",
      "torch.Size([1, 1, 22, 34])\n",
      "Training on image  284\n",
      "torch.Size([1, 1, 173, 21])\n",
      "Training on image  389\n",
      "torch.Size([1, 1, 34, 187])\n",
      "Training on image  209\n",
      "torch.Size([1, 1, 21, 140])\n",
      "Training on image  250\n",
      "torch.Size([1, 1, 182, 104])\n",
      "Training on image  165\n",
      "torch.Size([1, 1, 66, 310])\n",
      "Training on image  67\n",
      "torch.Size([1, 1, 165, 41])\n",
      "Training on image  102\n",
      "torch.Size([1, 1, 53, 283])\n",
      "Training on image  357\n",
      "torch.Size([1, 1, 185, 163])\n",
      "Training on image  215\n",
      "torch.Size([1, 1, 107, 225])\n",
      "Training on image  318\n",
      "torch.Size([1, 1, 23, 74])\n",
      "Training on image  118\n",
      "torch.Size([1, 1, 141, 158])\n",
      "Training on image  290\n",
      "torch.Size([1, 1, 155, 30])\n",
      "Training on image  351\n",
      "torch.Size([1, 1, 197, 31])\n",
      "Training on image  376\n",
      "torch.Size([1, 1, 53, 208])\n",
      "Training on image  258\n",
      "torch.Size([1, 1, 301, 103])\n",
      "Training on image  57\n",
      "torch.Size([1, 1, 42, 164])\n",
      "Training on image  302\n",
      "torch.Size([1, 1, 16, 148])\n",
      "Training on image  292\n",
      "torch.Size([1, 1, 266, 101])\n",
      "Training on image  177\n",
      "torch.Size([1, 1, 264, 264])\n",
      "Training on image  79\n",
      "torch.Size([1, 1, 94, 68])\n",
      "Training on image  421\n",
      "torch.Size([1, 1, 252, 183])\n",
      "Training on image  157\n",
      "torch.Size([1, 1, 169, 144])\n",
      "Training on image  12\n",
      "torch.Size([1, 1, 245, 25])\n",
      "Training on image  406\n",
      "torch.Size([1, 1, 139, 261])\n",
      "Training on image  386\n",
      "torch.Size([1, 1, 82, 268])\n",
      "Training on image  325\n",
      "torch.Size([1, 1, 28, 183])\n",
      "Training on image  123\n",
      "torch.Size([1, 1, 36, 199])\n",
      "Training on image  218\n",
      "torch.Size([1, 1, 373, 148])\n",
      "Training on image  242\n",
      "torch.Size([1, 1, 188, 306])\n",
      "Training on image  132\n",
      "torch.Size([1, 1, 54, 79])\n",
      "Training on image  235\n",
      "torch.Size([1, 1, 15, 56])\n",
      "Training on image  98\n",
      "torch.Size([1, 1, 97, 174])\n",
      "Training on image  247\n",
      "torch.Size([1, 1, 187, 272])\n",
      "Training on image  259\n",
      "torch.Size([1, 1, 90, 165])\n",
      "Training on image  361\n",
      "torch.Size([1, 1, 56, 20])\n",
      "Training on image  384\n",
      "torch.Size([1, 1, 51, 94])\n",
      "Training on image  172\n",
      "torch.Size([1, 1, 119, 126])\n",
      "Training on image  35\n",
      "torch.Size([1, 1, 49, 205])\n",
      "Training on image  149\n",
      "torch.Size([1, 1, 157, 284])\n",
      "Training on image  283\n",
      "torch.Size([1, 1, 41, 123])\n",
      "Training on image  380\n",
      "torch.Size([1, 1, 37, 309])\n",
      "Training on image  19\n",
      "torch.Size([1, 1, 163, 186])\n",
      "Training on image  156\n",
      "torch.Size([1, 1, 19, 384])\n",
      "Training on image  304\n",
      "torch.Size([1, 1, 181, 83])\n",
      "Training on image  103\n",
      "torch.Size([1, 1, 214, 163])\n",
      "Training on image  89\n",
      "torch.Size([1, 1, 234, 128])\n",
      "Training on image  239\n",
      "torch.Size([1, 1, 16, 59])\n",
      "Training on image  211\n",
      "torch.Size([1, 1, 55, 143])\n",
      "Training on image  285\n",
      "torch.Size([1, 1, 36, 65])\n",
      "Training on image  334\n",
      "torch.Size([1, 1, 227, 160])\n",
      "Training on image  169\n",
      "torch.Size([1, 1, 44, 208])\n",
      "Training on image  333\n",
      "torch.Size([1, 1, 298, 236])\n",
      "Training on image  223\n",
      "torch.Size([1, 1, 107, 21])\n",
      "Training on image  279\n",
      "torch.Size([1, 1, 133, 187])\n",
      "Training on image  412\n",
      "torch.Size([1, 1, 35, 51])\n",
      "Training on image  393\n",
      "torch.Size([1, 1, 64, 244])\n",
      "Training on image  262\n",
      "torch.Size([1, 1, 42, 202])\n",
      "Training on image  202\n",
      "torch.Size([1, 1, 58, 289])\n",
      "Training on image  385\n",
      "torch.Size([1, 1, 150, 343])\n",
      "Training on image  320\n",
      "torch.Size([1, 1, 69, 45])\n",
      "Training on image  44\n",
      "torch.Size([1, 1, 39, 217])\n",
      "Training on image  293\n",
      "torch.Size([1, 1, 85, 165])\n",
      "Training on image  369\n",
      "torch.Size([1, 1, 54, 208])\n",
      "Training on image  414\n",
      "torch.Size([1, 1, 217, 112])\n",
      "Training on image  68\n",
      "torch.Size([1, 1, 51, 140])\n",
      "Training on image  16\n",
      "torch.Size([1, 1, 269, 136])\n",
      "Training on image  43\n",
      "torch.Size([1, 1, 96, 41])\n",
      "Training on image  94\n",
      "torch.Size([1, 1, 183, 75])\n",
      "epoch Training done\n",
      "Epoch 1 training loss: 161.56754483655095\n",
      "Epoch 2 / 10\n",
      "Training...\n",
      "Model in training mode\n",
      "Training on image  76\n",
      "torch.Size([1, 1, 129, 30])\n",
      "Training on image  315\n",
      "torch.Size([1, 1, 95, 287])\n",
      "Training on image  127\n",
      "torch.Size([1, 1, 28, 210])\n",
      "Training on image  200\n",
      "torch.Size([1, 1, 182, 91])\n",
      "Training on image  332\n",
      "torch.Size([1, 1, 135, 76])\n",
      "Training on image  55\n",
      "torch.Size([1, 1, 116, 30])\n",
      "Training on image  151\n",
      "torch.Size([1, 1, 131, 118])\n",
      "Training on image  236\n",
      "torch.Size([1, 1, 222, 286])\n",
      "Training on image  184\n",
      "torch.Size([1, 1, 55, 134])\n",
      "Training on image  329\n",
      "torch.Size([1, 1, 203, 359])\n",
      "Training on image  361\n",
      "torch.Size([1, 1, 47, 20])\n",
      "Training on image  232\n",
      "torch.Size([1, 1, 304, 236])\n",
      "Training on image  176\n",
      "torch.Size([1, 1, 26, 20])\n",
      "Training on image  11\n",
      "torch.Size([1, 1, 49, 78])\n",
      "Training on image  18\n",
      "torch.Size([1, 1, 73, 128])\n",
      "Training on image  109\n",
      "torch.Size([1, 1, 251, 64])\n",
      "Training on image  340\n",
      "torch.Size([1, 1, 50, 291])\n",
      "Training on image  368\n",
      "torch.Size([1, 1, 247, 17])\n",
      "Training on image  99\n",
      "torch.Size([1, 1, 53, 307])\n",
      "Training on image  268\n",
      "torch.Size([1, 1, 86, 219])\n",
      "Training on image  44\n",
      "torch.Size([1, 1, 85, 41])\n",
      "Training on image  114\n",
      "torch.Size([1, 1, 134, 205])\n",
      "Training on image  299\n",
      "torch.Size([1, 1, 138, 122])\n",
      "Training on image  148\n",
      "torch.Size([1, 1, 47, 26])\n",
      "Training on image  380\n",
      "torch.Size([1, 1, 46, 261])\n",
      "Training on image  3\n",
      "torch.Size([1, 1, 196, 160])\n",
      "Training on image  125\n",
      "torch.Size([1, 1, 115, 39])\n",
      "Training on image  163\n",
      "torch.Size([1, 1, 76, 125])\n",
      "Training on image  80\n",
      "torch.Size([1, 1, 59, 97])\n",
      "Training on image  255\n",
      "torch.Size([1, 1, 113, 255])\n",
      "Training on image  189\n",
      "torch.Size([1, 1, 20, 81])\n",
      "Training on image  397\n",
      "torch.Size([1, 1, 101, 226])\n",
      "Training on image  359\n",
      "torch.Size([1, 1, 16, 150])\n",
      "Training on image  396\n",
      "torch.Size([1, 1, 265, 187])\n",
      "Training on image  301\n",
      "torch.Size([1, 1, 152, 490])\n",
      "Training on image  262\n",
      "torch.Size([1, 1, 25, 105])\n",
      "Training on image  298\n",
      "torch.Size([1, 1, 107, 115])\n",
      "Training on image  182\n",
      "torch.Size([1, 1, 88, 170])\n",
      "Training on image  409\n",
      "torch.Size([1, 1, 43, 55])\n",
      "Training on image  280\n",
      "torch.Size([1, 1, 32, 60])\n",
      "Training on image  129\n",
      "torch.Size([1, 1, 52, 169])\n",
      "Training on image  35\n",
      "torch.Size([1, 1, 40, 191])\n",
      "Training on image  331\n",
      "torch.Size([1, 1, 129, 165])\n",
      "Training on image  199\n",
      "torch.Size([1, 1, 320, 40])\n",
      "Training on image  100\n",
      "torch.Size([1, 1, 105, 255])\n",
      "Training on image  28\n",
      "torch.Size([1, 1, 125, 218])\n",
      "Training on image  188\n",
      "torch.Size([1, 1, 21, 100])\n",
      "Training on image  153\n",
      "torch.Size([1, 1, 58, 258])\n",
      "Training on image  172\n",
      "torch.Size([1, 1, 89, 62])\n",
      "Training on image  422\n",
      "torch.Size([1, 1, 108, 18])\n",
      "Training on image  192\n",
      "torch.Size([1, 1, 80, 256])\n",
      "Training on image  303\n",
      "torch.Size([1, 1, 67, 189])\n",
      "Training on image  215\n",
      "torch.Size([1, 1, 179, 81])\n",
      "Training on image  62\n",
      "torch.Size([1, 1, 44, 20])\n",
      "Training on image  205\n",
      "torch.Size([1, 1, 58, 255])\n",
      "Training on image  106\n",
      "torch.Size([1, 1, 114, 215])\n",
      "Training on image  333\n",
      "torch.Size([1, 1, 43, 293])\n",
      "Training on image  251\n",
      "torch.Size([1, 1, 147, 202])\n",
      "Training on image  412\n",
      "torch.Size([1, 1, 26, 128])\n",
      "Training on image  312\n",
      "torch.Size([1, 1, 236, 181])\n",
      "Training on image  341\n",
      "torch.Size([1, 1, 451, 380])\n",
      "Training on image  372\n",
      "torch.Size([1, 1, 141, 179])\n",
      "Training on image  10\n",
      "torch.Size([1, 1, 40, 25])\n",
      "Training on image  27\n",
      "torch.Size([1, 1, 129, 128])\n",
      "Training on image  0\n",
      "torch.Size([1, 1, 183, 160])\n",
      "Training on image  26\n",
      "torch.Size([1, 1, 64, 120])\n",
      "Training on image  141\n",
      "torch.Size([1, 1, 196, 268])\n",
      "Training on image  137\n",
      "torch.Size([1, 1, 49, 166])\n",
      "Training on image  242\n",
      "torch.Size([1, 1, 38, 109])\n",
      "Training on image  231\n",
      "torch.Size([1, 1, 17, 318])\n",
      "Training on image  220\n",
      "torch.Size([1, 1, 50, 177])\n",
      "Training on image  170\n",
      "torch.Size([1, 1, 294, 289])\n",
      "Training on image  47\n",
      "torch.Size([1, 1, 295, 45])\n",
      "Training on image  159\n",
      "torch.Size([1, 1, 45, 112])\n",
      "Training on image  334\n",
      "torch.Size([1, 1, 24, 71])\n",
      "Training on image  54\n",
      "torch.Size([1, 1, 172, 266])\n",
      "Training on image  306\n",
      "torch.Size([1, 1, 175, 48])\n",
      "Training on image  84\n",
      "torch.Size([1, 1, 148, 105])\n",
      "Training on image  238\n",
      "torch.Size([1, 1, 175, 41])\n",
      "Training on image  302\n",
      "torch.Size([1, 1, 54, 18])\n",
      "Training on image  175\n",
      "torch.Size([1, 1, 20, 102])\n",
      "Training on image  398\n",
      "torch.Size([1, 1, 83, 125])\n",
      "Training on image  64\n",
      "torch.Size([1, 1, 293, 73])\n",
      "Training on image  107\n",
      "torch.Size([1, 1, 65, 25])\n",
      "Training on image  102\n",
      "torch.Size([1, 1, 53, 246])\n",
      "Training on image  31\n",
      "torch.Size([1, 1, 72, 202])\n",
      "Training on image  419\n",
      "torch.Size([1, 1, 312, 94])\n",
      "Training on image  313\n",
      "torch.Size([1, 1, 155, 278])\n",
      "Training on image  138\n",
      "torch.Size([1, 1, 41, 215])\n",
      "Training on image  318\n",
      "torch.Size([1, 1, 59, 69])\n",
      "Training on image  23\n",
      "torch.Size([1, 1, 80, 316])\n",
      "Training on image  79\n",
      "torch.Size([1, 1, 38, 127])\n",
      "Training on image  399\n",
      "torch.Size([1, 1, 95, 109])\n",
      "Training on image  339\n",
      "torch.Size([1, 1, 34, 219])\n",
      "Training on image  405\n",
      "torch.Size([1, 1, 209, 84])\n",
      "Training on image  319\n",
      "torch.Size([1, 1, 55, 185])\n",
      "Training on image  93\n",
      "torch.Size([1, 1, 126, 27])\n",
      "Training on image  22\n",
      "torch.Size([1, 1, 27, 95])\n",
      "Training on image  210\n",
      "torch.Size([1, 1, 138, 92])\n",
      "Training on image  395\n",
      "torch.Size([1, 1, 127, 319])\n",
      "Training on image  209\n",
      "torch.Size([1, 1, 19, 96])\n",
      "Training on image  406\n",
      "torch.Size([1, 1, 120, 289])\n",
      "Training on image  144\n",
      "torch.Size([1, 1, 31, 48])\n",
      "Training on image  365\n",
      "torch.Size([1, 1, 78, 72])\n",
      "Training on image  69\n",
      "torch.Size([1, 1, 69, 57])\n",
      "Training on image  400\n",
      "torch.Size([1, 1, 93, 185])\n",
      "Training on image  115\n",
      "torch.Size([1, 1, 44, 133])\n",
      "Training on image  307\n",
      "torch.Size([1, 1, 34, 29])\n",
      "Training on image  112\n",
      "torch.Size([1, 1, 56, 233])\n",
      "Training on image  274\n",
      "torch.Size([1, 1, 34, 177])\n",
      "Training on image  1\n",
      "torch.Size([1, 1, 58, 66])\n",
      "Training on image  382\n",
      "torch.Size([1, 1, 162, 18])\n",
      "Training on image  2\n",
      "torch.Size([1, 1, 77, 35])\n",
      "Training on image  121\n",
      "torch.Size([1, 1, 138, 127])\n",
      "Training on image  13\n",
      "torch.Size([1, 1, 144, 121])\n",
      "Training on image  246\n",
      "torch.Size([1, 1, 165, 225])\n",
      "Training on image  39\n",
      "torch.Size([1, 1, 35, 147])\n",
      "Training on image  136\n",
      "torch.Size([1, 1, 112, 112])\n",
      "Training on image  212\n",
      "torch.Size([1, 1, 50, 186])\n",
      "Training on image  289\n",
      "torch.Size([1, 1, 70, 34])\n",
      "Training on image  36\n",
      "torch.Size([1, 1, 49, 103])\n",
      "Training on image  300\n",
      "torch.Size([1, 1, 70, 155])\n",
      "Training on image  370\n",
      "torch.Size([1, 1, 59, 181])\n",
      "Training on image  364\n",
      "torch.Size([1, 1, 40, 73])\n",
      "Training on image  277\n",
      "torch.Size([1, 1, 68, 21])\n",
      "Training on image  401\n",
      "torch.Size([1, 1, 47, 120])\n",
      "Training on image  87\n",
      "torch.Size([1, 1, 176, 214])\n",
      "Training on image  381\n",
      "torch.Size([1, 1, 257, 87])\n",
      "Training on image  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -2.2680e-02, -7.9968e-01, -6.2642e+00],\n",
      "        [ 8.0000e-01,  0.0000e+00,  0.0000e+00,  5.4985e+01],\n",
      "        [ 0.0000e+00, -7.9968e-01,  2.2680e-02,  1.3898e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 180, 16])\n",
      "Training on image  201\n",
      "torch.Size([1, 1, 85, 57])\n",
      "Training on image  42\n",
      "torch.Size([1, 1, 175, 314])\n",
      "Training on image  346\n",
      "torch.Size([1, 1, 274, 158])\n",
      "Training on image  243\n",
      "torch.Size([1, 1, 103, 25])\n",
      "Training on image  204\n",
      "torch.Size([1, 1, 32, 230])\n",
      "Training on image  111\n",
      "torch.Size([1, 1, 16, 145])\n",
      "Training on image  96\n",
      "torch.Size([1, 1, 63, 42])\n",
      "Training on image  57\n",
      "torch.Size([1, 1, 133, 137])\n",
      "Training on image  259\n",
      "torch.Size([1, 1, 64, 304])\n",
      "Training on image  354\n",
      "torch.Size([1, 1, 241, 305])\n",
      "Training on image  421\n",
      "torch.Size([1, 1, 100, 49])\n",
      "Training on image  367\n",
      "torch.Size([1, 1, 30, 165])\n",
      "Training on image  373\n",
      "torch.Size([1, 1, 43, 181])\n",
      "Training on image  174\n",
      "torch.Size([1, 1, 88, 188])\n",
      "Training on image  103\n",
      "torch.Size([1, 1, 203, 106])\n",
      "Training on image  295\n",
      "torch.Size([1, 1, 206, 185])\n",
      "Training on image  234\n",
      "torch.Size([1, 1, 125, 71])\n",
      "Training on image  40\n",
      "torch.Size([1, 1, 31, 115])\n",
      "Training on image  145\n",
      "torch.Size([1, 1, 42, 143])\n",
      "Training on image  304\n",
      "torch.Size([1, 1, 162, 185])\n",
      "Training on image  241\n",
      "torch.Size([1, 1, 45, 184])\n",
      "Training on image  411\n",
      "torch.Size([1, 1, 79, 152])\n",
      "Training on image  375\n",
      "torch.Size([1, 1, 79, 149])\n",
      "Training on image  160\n",
      "torch.Size([1, 1, 196, 107])\n",
      "Training on image  101\n",
      "torch.Size([1, 1, 86, 37])\n",
      "Training on image  414\n",
      "torch.Size([1, 1, 169, 170])\n",
      "Training on image  154\n",
      "torch.Size([1, 1, 139, 512])\n",
      "Training on image  4\n",
      "torch.Size([1, 1, 36, 171])\n",
      "Training on image  157\n",
      "torch.Size([1, 1, 88, 303])\n",
      "Training on image  347\n",
      "torch.Size([1, 1, 54, 187])\n",
      "Training on image  81\n",
      "torch.Size([1, 1, 108, 176])\n",
      "Training on image  291\n",
      "torch.Size([1, 1, 467, 28])\n",
      "Training on image  132\n",
      "torch.Size([1, 1, 34, 249])\n",
      "Training on image  294\n",
      "torch.Size([1, 1, 52, 166])\n",
      "Training on image  142\n",
      "torch.Size([1, 1, 276, 205])\n",
      "Training on image  37\n",
      "torch.Size([1, 1, 42, 199])\n",
      "Training on image  63\n",
      "torch.Size([1, 1, 62, 142])\n",
      "Training on image  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\transforms\\utility\\array.py:597: UserWarning: After SqueezeDim, img.affine is ill-posed: \n",
      "tensor([[ 0.0000e+00, -2.8356e-02, -9.9960e-01,  6.3793e+01],\n",
      "        [ 1.0002e+00,  0.0000e+00,  0.0000e+00,  6.0526e+01],\n",
      "        [ 0.0000e+00, -9.9982e-01,  2.8350e-02,  1.4476e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64).\n",
      "  warnings.warn(f\"After SqueezeDim, img.affine is ill-posed: \\n{img.affine}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 49, 160])\n",
      "Training on image  211\n",
      "torch.Size([1, 1, 18, 269])\n",
      "Training on image  75\n",
      "torch.Size([1, 1, 20, 248])\n",
      "Training on image  423\n",
      "torch.Size([1, 1, 37, 69])\n",
      "Training on image  167\n",
      "torch.Size([1, 1, 56, 311])\n",
      "Training on image  185\n",
      "torch.Size([1, 1, 171, 173])\n",
      "Training on image  324\n",
      "torch.Size([1, 1, 264, 318])\n",
      "Training on image  45\n",
      "torch.Size([1, 1, 30, 308])\n",
      "Training on image  240\n",
      "torch.Size([1, 1, 195, 83])\n",
      "Training on image  150\n",
      "torch.Size([1, 1, 22, 118])\n",
      "Training on image  206\n",
      "torch.Size([1, 1, 92, 18])\n",
      "Training on image  221\n",
      "torch.Size([1, 1, 245, 86])\n",
      "Training on image  418\n",
      "torch.Size([1, 1, 69, 265])\n",
      "Training on image  15\n",
      "torch.Size([1, 1, 153, 22])\n",
      "Training on image  351\n",
      "torch.Size([1, 1, 121, 149])\n",
      "Training on image  59\n",
      "torch.Size([1, 1, 99, 197])\n",
      "Training on image  223\n",
      "torch.Size([1, 1, 250, 63])\n",
      "Training on image  133\n",
      "torch.Size([1, 1, 294, 234])\n",
      "Training on image  33\n",
      "torch.Size([1, 1, 257, 314])\n",
      "Training on image  228\n",
      "torch.Size([1, 1, 79, 512])\n",
      "Training on image  191\n",
      "torch.Size([1, 1, 117, 16])\n",
      "Training on image  328\n",
      "torch.Size([1, 1, 42, 266])\n",
      "Training on image  117\n",
      "torch.Size([1, 1, 43, 202])\n",
      "Training on image  267\n",
      "torch.Size([1, 1, 146, 45])\n",
      "Training on image  50\n",
      "torch.Size([1, 1, 24, 170])\n",
      "Training on image  70\n",
      "torch.Size([1, 1, 135, 55])\n",
      "Training on image  8\n",
      "torch.Size([1, 1, 23, 35])\n",
      "Training on image  282\n",
      "torch.Size([1, 1, 53, 129])\n",
      "Training on image  77\n",
      "torch.Size([1, 1, 17, 156])\n",
      "Training on image  90\n",
      "torch.Size([1, 1, 178, 54])\n",
      "Training on image  327\n",
      "torch.Size([1, 1, 63, 287])\n",
      "Training on image  384\n",
      "torch.Size([1, 1, 169, 30])\n",
      "Training on image  379\n",
      "torch.Size([1, 1, 56, 300])\n",
      "Training on image  279\n",
      "torch.Size([1, 1, 29, 66])\n",
      "Training on image  309\n",
      "torch.Size([1, 1, 121, 280])\n",
      "Training on image  308\n",
      "torch.Size([1, 1, 51, 272])\n",
      "Training on image  314\n",
      "torch.Size([1, 1, 117, 115])\n",
      "Training on image  19\n",
      "torch.Size([1, 1, 165, 68])\n",
      "Training on image  143\n",
      "torch.Size([1, 1, 124, 200])\n",
      "Training on image  320\n",
      "torch.Size([1, 1, 252, 139])\n",
      "Training on image  155\n",
      "torch.Size([1, 1, 45, 82])\n",
      "Training on image  52\n",
      "torch.Size([1, 1, 19, 39])\n",
      "Training on image  208\n",
      "torch.Size([1, 1, 230, 206])\n",
      "Training on image  116\n",
      "torch.Size([1, 1, 61, 201])\n",
      "Training on image  85\n",
      "torch.Size([1, 1, 19, 164])\n",
      "Training on image  323\n",
      "torch.Size([1, 1, 36, 292])\n",
      "Training on image  244\n",
      "torch.Size([1, 1, 209, 299])\n",
      "Training on image  345\n",
      "torch.Size([1, 1, 92, 63])\n",
      "Training on image  413\n",
      "torch.Size([1, 1, 139, 160])\n",
      "Training on image  356\n",
      "torch.Size([1, 1, 98, 86])\n",
      "Training on image  86\n",
      "torch.Size([1, 1, 170, 176])\n",
      "Training on image  226\n",
      "torch.Size([1, 1, 110, 301])\n",
      "Training on image  21\n",
      "torch.Size([1, 1, 104, 91])\n",
      "Training on image  193\n",
      "torch.Size([1, 1, 180, 45])\n",
      "Training on image  271\n",
      "torch.Size([1, 1, 169, 32])\n",
      "Training on image  377\n",
      "torch.Size([1, 1, 82, 217])\n",
      "Training on image  270\n",
      "torch.Size([1, 1, 21, 213])\n",
      "Training on image  248\n",
      "torch.Size([1, 1, 136, 288])\n",
      "Training on image  216\n",
      "torch.Size([1, 1, 65, 156])\n",
      "Training on image  229\n",
      "torch.Size([1, 1, 208, 160])\n",
      "Training on image  17\n",
      "torch.Size([1, 1, 191, 287])\n",
      "Training on image  98\n",
      "torch.Size([1, 1, 245, 69])\n",
      "Training on image  284\n",
      "torch.Size([1, 1, 60, 52])\n",
      "Training on image  257\n",
      "torch.Size([1, 1, 260, 87])\n",
      "Training on image  317\n",
      "torch.Size([1, 1, 511, 145])\n",
      "Training on image  67\n",
      "torch.Size([1, 1, 60, 62])\n",
      "Training on image  276\n",
      "torch.Size([1, 1, 46, 299])\n",
      "Training on image  95\n",
      "torch.Size([1, 1, 318, 152])\n",
      "Training on image  156\n",
      "torch.Size([1, 1, 46, 123])\n",
      "Training on image  363\n",
      "torch.Size([1, 1, 51, 180])\n",
      "Training on image  230\n",
      "torch.Size([1, 1, 263, 65])\n",
      "Training on image  61\n",
      "torch.Size([1, 1, 55, 16])\n",
      "Training on image  195\n",
      "torch.Size([1, 1, 41, 47])\n",
      "Training on image  261\n",
      "torch.Size([1, 1, 296, 246])\n",
      "Training on image  275\n",
      "torch.Size([1, 1, 18, 45])\n",
      "Training on image  197\n",
      "torch.Size([1, 1, 48, 231])\n",
      "Training on image  164\n",
      "torch.Size([1, 1, 41, 422])\n",
      "Training on image  218\n",
      "torch.Size([1, 1, 194, 32])\n",
      "Training on image  310\n",
      "torch.Size([1, 1, 26, 143])\n",
      "Training on image  166\n",
      "torch.Size([1, 1, 21, 25])\n",
      "Training on image  224\n",
      "torch.Size([1, 1, 42, 69])\n",
      "Training on image  126\n",
      "torch.Size([1, 1, 39, 106])\n",
      "Training on image  6\n",
      "torch.Size([1, 1, 40, 207])\n",
      "Training on image  48\n",
      "torch.Size([1, 1, 64, 196])\n",
      "Training on image  118\n",
      "torch.Size([1, 1, 151, 45])\n",
      "Training on image  73\n",
      "torch.Size([1, 1, 170, 170])\n",
      "Training on image  20\n",
      "torch.Size([1, 1, 65, 33])\n",
      "Training on image  161\n",
      "torch.Size([1, 1, 162, 84])\n",
      "Training on image  378\n",
      "torch.Size([1, 1, 56, 57])\n",
      "Training on image  233\n",
      "torch.Size([1, 1, 43, 297])\n",
      "Training on image  219\n",
      "torch.Size([1, 1, 60, 58])\n",
      "Training on image  135\n",
      "torch.Size([1, 1, 20, 155])\n",
      "Training on image  350\n",
      "torch.Size([1, 1, 148, 69])\n",
      "Training on image  252\n",
      "torch.Size([1, 1, 29, 313])\n",
      "Training on image  393\n",
      "torch.Size([1, 1, 39, 152])\n",
      "Training on image  46\n",
      "torch.Size([1, 1, 110, 184])\n",
      "Training on image  89\n",
      "torch.Size([1, 1, 31, 306])\n",
      "Training on image  278\n",
      "torch.Size([1, 1, 34, 18])\n",
      "Training on image  296\n",
      "torch.Size([1, 1, 128, 173])\n",
      "Training on image  390\n",
      "torch.Size([1, 1, 69, 38])\n",
      "Training on image  239\n",
      "torch.Size([1, 1, 85, 23])\n",
      "Training on image  123\n",
      "torch.Size([1, 1, 126, 33])\n",
      "Training on image  119\n",
      "torch.Size([1, 1, 76, 27])\n",
      "Training on image  97\n",
      "torch.Size([1, 1, 83, 61])\n",
      "Training on image  25\n",
      "torch.Size([1, 1, 18, 37])\n",
      "Training on image  7\n",
      "torch.Size([1, 1, 25, 298])\n",
      "Training on image  288\n",
      "torch.Size([1, 1, 25, 194])\n",
      "Training on image  190\n",
      "torch.Size([1, 1, 190, 162])\n",
      "Training on image  130\n",
      "torch.Size([1, 1, 21, 245])\n",
      "Training on image  424\n",
      "torch.Size([1, 1, 96, 23])\n",
      "Training on image  91\n",
      "torch.Size([1, 1, 306, 104])\n",
      "Training on image  425\n",
      "torch.Size([1, 1, 104, 185])\n",
      "Training on image  374\n",
      "torch.Size([1, 1, 41, 257])\n",
      "Training on image  225\n",
      "torch.Size([1, 1, 132, 128])\n",
      "Training on image  388\n",
      "torch.Size([1, 1, 46, 22])\n",
      "Training on image  311\n",
      "torch.Size([1, 1, 56, 83])\n",
      "Training on image  325\n",
      "torch.Size([1, 1, 21, 26])\n",
      "Training on image  24\n",
      "torch.Size([1, 1, 47, 87])\n",
      "Training on image  249\n",
      "torch.Size([1, 1, 84, 225])\n",
      "Training on image  43\n",
      "torch.Size([1, 1, 275, 169])\n",
      "Training on image  408\n",
      "torch.Size([1, 1, 42, 129])\n",
      "Training on image  383\n",
      "torch.Size([1, 1, 52, 155])\n",
      "Training on image  348\n",
      "torch.Size([1, 1, 31, 96])\n",
      "Training on image  41\n",
      "torch.Size([1, 1, 66, 146])\n",
      "Training on image  16\n",
      "torch.Size([1, 1, 58, 118])\n",
      "Training on image  171\n",
      "torch.Size([1, 1, 152, 216])\n",
      "Training on image  180\n",
      "torch.Size([1, 1, 15, 173])\n",
      "Training on image  158\n",
      "torch.Size([1, 1, 118, 33])\n",
      "Training on image  110\n",
      "torch.Size([1, 1, 234, 240])\n",
      "Training on image  147\n",
      "torch.Size([1, 1, 97, 54])\n",
      "Training on image  178\n",
      "torch.Size([1, 1, 134, 246])\n",
      "Training on image  68\n",
      "torch.Size([1, 1, 185, 17])\n",
      "Training on image  265\n",
      "torch.Size([1, 1, 49, 209])\n",
      "Training on image  152\n",
      "torch.Size([1, 1, 86, 99])\n",
      "Training on image  82\n",
      "torch.Size([1, 1, 34, 249])\n",
      "Training on image  29\n",
      "torch.Size([1, 1, 166, 145])\n",
      "Training on image  360\n",
      "torch.Size([1, 1, 121, 270])\n",
      "Training on image  410\n",
      "torch.Size([1, 1, 175, 259])\n",
      "Training on image  105\n",
      "torch.Size([1, 1, 180, 167])\n",
      "Training on image  403\n",
      "torch.Size([1, 1, 93, 59])\n",
      "Training on image  420\n",
      "torch.Size([1, 1, 46, 221])\n",
      "Training on image  404\n",
      "torch.Size([1, 1, 194, 48])\n",
      "Training on image  387\n",
      "torch.Size([1, 1, 254, 71])\n",
      "Training on image  254\n",
      "torch.Size([1, 1, 116, 231])\n",
      "Training on image  92\n",
      "torch.Size([1, 1, 147, 53])\n",
      "Training on image  14\n",
      "torch.Size([1, 1, 152, 295])\n",
      "Training on image  293\n",
      "torch.Size([1, 1, 150, 179])\n",
      "Training on image  290\n",
      "torch.Size([1, 1, 107, 226])\n",
      "Training on image  337\n",
      "torch.Size([1, 1, 211, 231])\n",
      "Training on image  258\n",
      "torch.Size([1, 1, 99, 152])\n",
      "Training on image  72\n",
      "torch.Size([1, 1, 144, 29])\n",
      "Training on image  71\n",
      "torch.Size([1, 1, 27, 237])\n",
      "Training on image  287\n",
      "torch.Size([1, 1, 308, 158])\n",
      "Training on image  213\n",
      "torch.Size([1, 1, 67, 233])\n",
      "Training on image  168\n",
      "torch.Size([1, 1, 68, 19])\n",
      "Training on image  283\n",
      "torch.Size([1, 1, 273, 246])\n",
      "Training on image  336\n",
      "torch.Size([1, 1, 222, 79])\n",
      "Training on image  169\n",
      "torch.Size([1, 1, 228, 278])\n",
      "Training on image  32\n",
      "torch.Size([1, 1, 298, 265])\n",
      "Training on image  407\n",
      "torch.Size([1, 1, 56, 140])\n",
      "Training on image  286\n",
      "torch.Size([1, 1, 41, 277])\n",
      "Training on image  273\n",
      "torch.Size([1, 1, 57, 204])\n",
      "Training on image  227\n",
      "torch.Size([1, 1, 160, 155])\n",
      "Training on image  207\n",
      "torch.Size([1, 1, 137, 64])\n",
      "Training on image  181\n",
      "torch.Size([1, 1, 62, 151])\n",
      "Training on image  321\n",
      "torch.Size([1, 1, 34, 181])\n",
      "Training on image  128\n",
      "torch.Size([1, 1, 89, 157])\n",
      "Training on image  330\n",
      "torch.Size([1, 1, 35, 317])\n",
      "Training on image  269\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Define the training loop\n",
    "def training_one_epoch(model):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    queue_line = np.arange(train_dataset.length)\n",
    "    np.random.shuffle(queue_line) \n",
    "    for i in queue_line:\n",
    "        image, label = train_dataset[i]\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return model, running_loss / len(train_dataset)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epochs}\")\n",
    "    model, train_loss = training_one_epoch(model)\n",
    "    print(f\"Epoch {epoch + 1} training loss: {train_loss}\")\n",
    "\n",
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
